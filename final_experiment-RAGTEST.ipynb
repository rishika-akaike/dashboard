{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a8396d7-609f-4854-8f82-7b44fe12815b",
   "metadata": {},
   "source": [
    "## Experiments with db_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bcc8324-bf5c-4f03-a6ce-dc54883cbd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine,text\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e42f6a-dc96-47d3-a663-64883cdbb9c0",
   "metadata": {},
   "source": [
    "### Pydantic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "396edc76-ac48-41ed-868a-3b501a8b5728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel,Field\n",
    "from typing import Dict,List,Literal, Optional\n",
    "from pydantic import BaseModel,Field\n",
    "from typing import Dict,List,Literal, Optional,Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e269f05-68ad-4b0d-9f29-a799a9eb1f19",
   "metadata": {},
   "source": [
    "### Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b305560-cb58-47d2-81c2-6239bc2ac7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate,PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4dcb0c5-a267-4e83-aae4-b7b2171326fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4796a1df-3989-4179-a4e5-3146512d6bcb",
   "metadata": {},
   "source": [
    "### Vector DB and RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f222db24-d31e-456a-b4dd-79c4d25d5c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57d846e-1aab-4b23-842b-e8de0bddb2cf",
   "metadata": {},
   "source": [
    "### Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "109c4c5d-ccf8-420f-ba9e-f0639a1299c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b5b27f-7418-4b48-b384-7f94ac00a5d1",
   "metadata": {},
   "source": [
    "##  Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25a79e0a-7f3c-4a6c-a66f-7ee46b29ee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "def get_all_tables_metadata(engine):\n",
    "    query = \"\"\"\n",
    "    SELECT TABLE_NAME, COLUMN_NAME, DATA_TYPE \n",
    "    FROM information_schema.columns\n",
    "    WHERE table_schema = 'test_db_tables'\n",
    "    \"\"\"\n",
    "    result = pd.read_sql(text(query), engine)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "180d0a0f-c04c-48c7-82e0-d2c54baf443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "username = 'user_demo'\n",
    "password = 'password_demo'\n",
    "host = 'chat-csv.c9pssgmnnguu.us-west-2.rds.amazonaws.com'\n",
    "port = 3306\n",
    "database = 'test_db_tables'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00043455-af39-4c7d-8f63-c5896a60e3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f'mysql+pymysql://{username}:{password}@{host}:{port}/{database}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f929a4c9-caa3-49eb-820c-420f99f6870e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TABLE_NAME</th>\n",
       "      <th>COLUMN_NAME</th>\n",
       "      <th>DATA_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auto_insurance</td>\n",
       "      <td>Customer</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auto_insurance</td>\n",
       "      <td>State</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>auto_insurance</td>\n",
       "      <td>Customer Lifetime Value</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>auto_insurance</td>\n",
       "      <td>Response</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>auto_insurance</td>\n",
       "      <td>Coverage</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>sri_dataset</td>\n",
       "      <td>d5_g</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>sri_dataset</td>\n",
       "      <td>d6</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>sri_dataset</td>\n",
       "      <td>d7</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>unemployment_level</td>\n",
       "      <td>DATE</td>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>unemployment_level</td>\n",
       "      <td>UNEMPLOY</td>\n",
       "      <td>bigint</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>719 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             TABLE_NAME              COLUMN_NAME DATA_TYPE\n",
       "0        auto_insurance                 Customer      text\n",
       "1        auto_insurance                    State      text\n",
       "2        auto_insurance  Customer Lifetime Value    double\n",
       "3        auto_insurance                 Response      text\n",
       "4        auto_insurance                 Coverage      text\n",
       "..                  ...                      ...       ...\n",
       "714         sri_dataset                     d5_g    double\n",
       "715         sri_dataset                       d6      text\n",
       "716         sri_dataset                       d7      text\n",
       "717  unemployment_level                     DATE  datetime\n",
       "718  unemployment_level                 UNEMPLOY    bigint\n",
       "\n",
       "[719 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata=get_all_tables_metadata(engine)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73700842-f16b-4a45-9714-1cfe786327cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChartClass(BaseModel):\n",
    "    thought: str = Field(...,description = \"Thought Process behind decision for deciding possibility of a visualization for the given query on this dataset \")\n",
    "    is_chart_possible: Literal[\"Yes\", \"No\",\"rephrase\"] = Field(\n",
    "        ...,\n",
    "        description=\"Indicates if a chart is possible based on the query. Must be either 'Yes', 'No' or 'rephrase', use rephrase if some extra info can help in deciding whether to visualize.\",\n",
    "    )\n",
    "    tables_columns: Dict[str, List[str]] = Field(\n",
    "        default=None,\n",
    "        description=\"Dictionary of tables and their corresponding columns required for the visualization based on the question.\"\n",
    "    )\n",
    "    chart_type: str = Field(\n",
    "        ...,\n",
    "        description=\"Type of chart suitable for this visualization (e.g., line, multiline, bar, pie).\",\n",
    "    )\n",
    "    type: Literal[\n",
    "        \"time_series\", \"group_aggregates\", \"combination\", \"multilevel_categorical\",\"relational\",\"distribution\",\"\"\n",
    "    ] = Field(default = None, description=\"\")\n",
    "    is_derived: Literal[True,False] =  Field(...,description = \"whether this metric could be be derived using some mathematical operations between 2 columns \")\n",
    "   \n",
    "\n",
    "class RejectClass(BaseModel):\n",
    "    reason:str = Field(...,description = \"Reason for rejecting possibility of visualization, need to crisp and polite\")\n",
    "    suggested_alternatives: List[str] = Field(...,description = \"list of alternative questions which a user could ask on this dataset which could give a visualization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc9e55c5-6ccb-4074-9b5e-75506f2cf780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RephraseClass(BaseModel):\n",
    "    thought: str = Field(...,description=\"Thought process used while rephrasing the query, always take cue from the database metadata given\")\n",
    "    rephrased_query:str = Field(...,description= \"Rephrased query on which a visualization is plausible based on the given chart type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08e4beee-5e5d-406b-ab3b-ba493532d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChartConfig(BaseModel):\n",
    "    x_axis: str = Field(\n",
    "        ...,\n",
    "        description=\"Column of the dataset to be on the x-axis for the given visualization. It should be a column present in the dataset.\",\n",
    "    )\n",
    "    y_axis: Any = Field(default = None, description=\"Column of the dataset to be on the y-axis It will be None in case of no y-axis.\")\n",
    "    binning: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Binning for time series or combinations, either 'yearly' or 'monthly'. Only fill in case of time series or combinations.\",\n",
    "    )\n",
    "    heading: str = Field(..., description=\"The heading for the visualization.\")\n",
    "    group_by: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Column of the dataset on which grouping is to be done. Leave blank for time series. Ensure it is a column present in the dataset.\",\n",
    "    )\n",
    "    operation: Literal[\"mean\", \"max\", \"sum\",\"count\",\"none\",None,\"\"] = Field(\n",
    "        default=None,\n",
    "        description=\"Operation to be inferred from the question. It is either 'mean', 'max', or 'sum'.\",\n",
    "    )\n",
    "    chart_type: str = Field(\n",
    "        ...,\n",
    "        description=\"The chart type to be used for visualization (e.g., bar, line, multiline).\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf5f9f1-9da4-4013-844e-3e027f49f31d",
   "metadata": {},
   "source": [
    "## Create an LLM class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9465589-ec17-4e4b-97a3-44073cb38135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_response(prompt_file_path:str,pydantic_class=None,llm=None,input_variables:dict=None):\n",
    "    with open(prompt_file_path,'r') as f:\n",
    "        prompt = f.read()\n",
    "    if pydantic_class:\n",
    "        parser = PydanticOutputParser(pydantic_object=pydantic_class)\n",
    "        chat_prompt = PromptTemplate(template = prompt,input_variables=list(input_variables.keys()),partial_variables={\"format_instructions\": parser.get_format_instructions()})\n",
    "        brain = chat_prompt|llm|parser\n",
    "    else:\n",
    "        chat_prompt = PromptTemplate(template = prompt,input_variables=list(input_variables.keys()))\n",
    "        brain = chat_prompt|llm\n",
    "        \n",
    "    output =brain.invoke(input_variables)\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89aa3b60-fe49-47c9-b148-cbb11f17ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\",model_kwargs={\"response_format\": {\"type\": \"json_object\"}})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa5ff21-09df-4c21-8f79-223602eab9d4",
   "metadata": {},
   "source": [
    "## MYSQL  RESULTANT DF FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f646ae8-94b1-45bf-9f44-600287ecb7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySQLPandasDF:\n",
    "    def __init__(self, chart_config, connection, table, db_type=\"mysql\", filter_columns=None,derived = None):\n",
    "        \"\"\"\n",
    "        Initializes the MySQLPandasDF object with the given parameters.\n",
    "        \"\"\"\n",
    "        self.chart_config = chart_config\n",
    "        self.connection = connection\n",
    "        self.table = table\n",
    "        self.db_type = db_type\n",
    "        self.filter_columns = filter_columns\n",
    "        self.derived = derived\n",
    "        self.freq_dict = {\n",
    "            \"business_day\": \"B\",\n",
    "            \"calendar_day\": \"D\",\n",
    "            \"weekly\": \"W\",\n",
    "            \"monthly\": \"M\",\n",
    "            \"quarterly\": \"Q\",\n",
    "            \"yearly\": \"A\",\n",
    "            \"hourly\": \"H\",\n",
    "            \"minutely\": \"T\",\n",
    "            \"secondly\": \"S\",\n",
    "            \"milliseconds\": \"L\",\n",
    "            \"microseconds\": \"U\",\n",
    "            \"nanoseconds\": \"N\",\n",
    "            \"daily\": \"D\",\n",
    "        }\n",
    "\n",
    "    def _apply_filters(self):\n",
    "        filter_columns = self.filter_columns\n",
    "        sql_query = \"WHERE \"\n",
    "        for col, conditions in filter_columns.get(\"numerical_columns\", {}).items():\n",
    "            start_value = conditions.get(\"start_value\")\n",
    "            end_value = conditions.get(\"end_value\")\n",
    "            if start_value is not None:\n",
    "                if sql_query != \"WHERE \":\n",
    "                    sql_query += f' AND \"{col}\">={start_value}'\n",
    "                else:\n",
    "                    sql_query += f'\"{col}\">={start_value}'\n",
    "            if end_value is not None:\n",
    "                if sql_query != \"WHERE \":\n",
    "                    sql_query += f' AND \"{col}\"<={end_value}'\n",
    "                else:\n",
    "                    sql_query += f' \"{col}\"<={end_value}'\n",
    "\n",
    "        # Apply filters for date columns\n",
    "        for col, conditions in filter_columns.get(\"date_columns\", {}).items():\n",
    "            start_date = conditions.get(\"start_date\")\n",
    "            end_date = conditions.get(\"end_date\")\n",
    "            if start_date is not None:\n",
    "                if sql_query != \"WHERE \":\n",
    "                    sql_query += f\" AND DATE(`{col}`)>=DATE('{start_date}')\"\n",
    "                else:\n",
    "                    sql_query += f\"DATE(`{col}`)>=DATE('{start_date}')\"\n",
    "            if end_date is not None:\n",
    "                if sql_query != \"WHERE \":\n",
    "                    sql_query += f\" AND DATE(`{col}`)<=DATE('{end_date}')\"\n",
    "                else:\n",
    "                    sql_query += f\" DATE(`{col}`)<=DATE('{end_date}')\"\n",
    "        for col, values in filter_columns.get(\"categorical_columns\", {}).items():\n",
    "            if values:\n",
    "                formatted_values = \", \".join([f\"'{val}'\" for val in values])\n",
    "                if sql_query != \"WHERE \":\n",
    "                    sql_query += f' AND \"{col}\" in ({formatted_values})'\n",
    "\n",
    "                else:\n",
    "                    sql_query += f'\"{col}\" in ({formatted_values})'\n",
    "        if sql_query == \"WHERE \":\n",
    "            sql_query = \"\"\n",
    "        return sql_query.replace('\"', \"`\")\n",
    "\n",
    "    def _get_column_data_types(self, x_axis, y_axis = None):\n",
    "        \"\"\"\n",
    "        Retrieves the data types of the specified columns from the database for MySQL.\n",
    "        \"\"\"\n",
    "        if y_axis:\n",
    "            col_data_type_query = f\"\"\"\n",
    "                SELECT COLUMN_NAME, DATA_TYPE\n",
    "                FROM INFORMATION_SCHEMA.COLUMNS\n",
    "                WHERE TABLE_NAME = '{self.table}'\n",
    "                  AND COLUMN_NAME IN ('{x_axis}', '{y_axis}')\n",
    "            \"\"\"\n",
    "        else:\n",
    "            col_data_type_query = f\"\"\"\n",
    "                SELECT COLUMN_NAME, DATA_TYPE\n",
    "                FROM INFORMATION_SCHEMA.COLUMNS\n",
    "                WHERE TABLE_NAME = '{self.table}'\n",
    "                  AND COLUMN_NAME = '{x_axis}'\n",
    "            \"\"\"\n",
    "        df = pd.read_sql_query(text(col_data_type_query), self.connection)\n",
    "        return df\n",
    "\n",
    "    def _generate_timeseries_resultant_df(self):\n",
    "        \"\"\"\n",
    "        Generates a pandas DataFrame for time series data based on the chart configuration for MySQL.\n",
    "        \"\"\"\n",
    "        x_axis, y_axis, binning, operation, group_by,formula = self._extract_chart_config()\n",
    "        col_data_type = self._get_column_data_types(x_axis, y_axis)\n",
    "        date_type = col_data_type.loc[\n",
    "            col_data_type[\"column_name\".upper()] == x_axis, \"data_type\".upper()\n",
    "        ].values[0]\n",
    "        if formula:\n",
    "            y_val = formula\n",
    "            operation = \"\"\n",
    "        else:\n",
    "            y_val = y_axis\n",
    "            \n",
    "        if not binning:\n",
    "            binning = \"monthly\"\n",
    "        if operation == None :\n",
    "            operation = \"AVG\"\n",
    "        if operation not in [\"count\",\"sum\"] :\n",
    "            operation = \"AVG\"\n",
    "        clause = \"\"\n",
    "        if self.filter_columns:\n",
    "            clause = self._apply_filters()\n",
    "            if clause != \"WHERE \":\n",
    "                clause = f\" {clause}\"\n",
    "\n",
    "        binning_clause = (\n",
    "            f\"YEAR(`{x_axis}`)\"\n",
    "            if binning.lower() == \"yearly\"\n",
    "            else f\"YEAR(`{x_axis}`), MONTH(`{x_axis}`)\"\n",
    "        )\n",
    "        if date_type == \"text\":\n",
    "            \n",
    "            sql_query = (\n",
    "                f\"\"\"\n",
    "                SELECT DATE(`{x_axis}`)AS `{x_axis}`,\n",
    "                   {operation}({y_val}) AS {y_axis}\n",
    "            FROM `{self.table}`\"\"\"\n",
    "                + clause\n",
    "                + f\"\"\" \n",
    "            GROUP BY {binning_clause}\n",
    "            ORDER BY {binning_clause} ASC\n",
    "            \"\"\"\n",
    "            )\n",
    "\n",
    "        elif date_type in [\"int\", \"bigint\", \"integer\"]:\n",
    "            sql_query = (\n",
    "                f\"\"\"\n",
    "                SELECT `{x_axis}` AS `{x_axis}`,\n",
    "                       {operation}({y_val}) AS {y_axis}\n",
    "                FROM {self.table}\n",
    "                \"\"\"\n",
    "                + clause\n",
    "                + f\"\"\"\n",
    "                GROUP BY `{x_axis}`\n",
    "                ORDER BY `{x_axis}` ASC\n",
    "            \"\"\"\n",
    "            )\n",
    "            return pd.read_sql_query(text(sql_query), self.connection)\n",
    "        # Adjusted for MySQL's date functions\n",
    "        else:\n",
    "            sql_query = (\n",
    "                f\"\"\"\n",
    "                SELECT `{x_axis}` AS `{x_axis}`,\n",
    "                       {operation}({y_val}) AS {y_axis}\n",
    "                FROM `{self.table}` \"\"\"\n",
    "                + clause\n",
    "                + f\"\"\" \n",
    "                GROUP BY YEAR(`{x_axis}`),MONTH({x_axis})\n",
    "                ORDER BY YEAR(`{x_axis}`),MONTH({x_axis}) ASC\n",
    "            \"\"\"\n",
    "            )\n",
    "        sql_query = sql_query.replace('\"', \"`\")\n",
    "        date_format = {\"yearly\": \"%Y\", \"monthly\": \"%Y-%m\", \"daily\": \"%Y-%m-%d\"}\n",
    "        result = self.connection.execute(text(sql_query)).fetchall()\n",
    "        formatted_results = []\n",
    "        for row in result:\n",
    "            formatted_date = row[0].strftime(date_format[binning])\n",
    "            formatted_results.append({x_axis: formatted_date, y_axis: row[1]})\n",
    "\n",
    "        # column_names = [desc[0] for desc in self.connection.description]\n",
    "        return pd.DataFrame(formatted_results)\n",
    "\n",
    "    def _generate_groupaggregate_resultant_df(self):\n",
    "        \"\"\"\n",
    "        Generates a pandas DataFrame for grouped aggregate data based on the chart configuration for MySQL.\n",
    "        \"\"\"\n",
    "        x_axis, y_axis, binning, operation, group_by,formula = self._extract_chart_config()\n",
    "        if formula:\n",
    "            y_val =formula\n",
    "            operation = \"\"\n",
    "        else:\n",
    "            y_val = y_axis\n",
    "            \n",
    "        clause = \"\"\n",
    "        if self.filter_columns:\n",
    "            clause = self._apply_filters()\n",
    "            if clause != \"WHERE \":\n",
    "                clause = f\" {clause}\"\n",
    "        if operation == \"mean\":\n",
    "            operation = \"AVG\"\n",
    "        sql_query = (\n",
    "            f\"\"\"\n",
    "            SELECT `{x_axis}`,\n",
    "                   {operation}({y_axis}) AS {y_axis}\n",
    "            FROM `{self.table}`\"\"\"\n",
    "            + clause\n",
    "            + f\" GROUP BY `{x_axis}`\"\n",
    "        )\n",
    "        sql_query = sql_query.replace('\"', \"`\")\n",
    "        df = pd.read_sql_query(text(sql_query), self.connection)\n",
    "        return df\n",
    "\n",
    "    def _generate_combination_resultant_df(self):\n",
    "        \"\"\"\n",
    "        Generates a pandas DataFrame combining time series and grouped aggregate data based on the chart configuration for MySQL.\n",
    "        \"\"\"\n",
    "        x_axis, y_axis, binning, operation, group_by,formula = self._extract_chart_config()\n",
    "        if formula:\n",
    "            y_val =formula\n",
    "            operation = \"\"\n",
    "        else:\n",
    "            y_val = y_axis\n",
    "        col_data_type = self._get_column_data_types(x_axis, y_axis)\n",
    "        date_type = col_data_type.loc[\n",
    "            col_data_type[\"column_name\".upper()] == x_axis, \"data_type\".upper()\n",
    "        ].values[0]\n",
    "        clause = \"\"\n",
    "        if self.filter_columns:\n",
    "            clause = self._apply_filters()\n",
    "            if clause != \"WHERE \":\n",
    "                clause = f\" {clause}\"\n",
    "        date_part = \"YEAR\" if binning == \"yearly\" else \"MONTH\"\n",
    "        date_format = {\"yearly\": \"%Y\", \"monthly\": \"%Y-%m\", \"daily\": \"%Y-%m-%d\"}\n",
    "        if operation == \"\" or operation == \"mean\":\n",
    "            operation = \"AVG\"\n",
    "        # Adjusted for MySQL's date functions\n",
    "        if date_type == \"text\":\n",
    "            sql_query = (\n",
    "                f\"\"\"\n",
    "                SELECT DATE(`{x_axis}` AS `{x_axis}`,\n",
    "                   {operation}({y_axis}) AS {y_axis},{group_by}\n",
    "            FROM `{self.table}`\"\"\"\n",
    "                + clause\n",
    "                + f\"\"\"\n",
    "            GROUP BY {group_by},DATE(`{x_axis}`)\n",
    "            ORDER BY DATE(`{x_axis}`) ASC\n",
    "            \"\"\"\n",
    "            )\n",
    "\n",
    "        elif date_type in [\"int\", \"bigint\", \"integer\"]:\n",
    "            sql_query = (\n",
    "                f\"\"\"\n",
    "                SELECT `{x_axis}` AS `{x_axis}`,\n",
    "                       {operation}({y_axis}) AS `{y_axis}`,\n",
    "                       `{group_by}`\n",
    "                FROM `{self.table}` \"\"\"\n",
    "                + clause\n",
    "                + f\"\"\"\n",
    "                GROUP BY `{group_by}`, `{x_axis}`\n",
    "                ORDER BY `{x_axis}` ASC\n",
    "            \"\"\"\n",
    "            )\n",
    "\n",
    "        # Adjusted for MySQL's date functions\n",
    "        else:\n",
    "            sql_query = (\n",
    "                f\"\"\"\n",
    "                SELECT `{x_axis}` AS `{x_axis}`,\n",
    "                       {operation}({y_axis}) AS `{y_axis}`,`{group_by}`\n",
    "                FROM `{self.table}`\"\"\"\n",
    "                + clause\n",
    "                + f\"\"\"\n",
    "                GROUP BY `{group_by}`,{x_axis}\n",
    "                ORDER BY `{x_axis}` ASC\n",
    "            \"\"\"\n",
    "            )\n",
    "        sql_query = sql_query.replace('\"', \"`\")\n",
    "        date_format = {\"yearly\": \"%Y\", \"monthly\": \"%Y-%m\", \"daily\": \"%Y-%m-%d\"}\n",
    "        result = self.connection.execute(text(sql_query)).fetchall()\n",
    "        formatted_results = []\n",
    "        for row in result:\n",
    "            formatted_date = row[0].strftime(date_format[binning])\n",
    "            formatted_results.append({x_axis: formatted_date, y_axis: row[1]})\n",
    "\n",
    "        # column_names = [desc[0] for desc in self.connection.description]\n",
    "        return pd.DataFrame(formatted_results)\n",
    "\n",
    "    def _generate_multilevelcategorical_resultant_df(self):\n",
    "        x_axis, y_axis, binning, operation, group_by,formula = self._extract_chart_config()\n",
    "        col_data_type = self._get_column_data_types(x_axis, y_axis)\n",
    "        date_type = col_data_type.loc[\n",
    "            col_data_type[\"column_name\".upper()] == x_axis, \"data_type\".upper()\n",
    "        ].values[0]\n",
    "        clause = \"\"\n",
    "        if self.filter_columns:\n",
    "            clause = self._apply_filters()\n",
    "            if clause != \"WHERE \":\n",
    "                clause = f\" {clause}\"\n",
    "        date_part = \"YEAR\" if binning == \"yearly\" else \"MONTH\"\n",
    "        date_format = {\"yearly\": \"%Y\", \"monthly\": \"%Y-%m\", \"daily\": \"%Y-%m-%d\"}\n",
    "        if operation == \"\" or operation == \"mean\":\n",
    "            operation = \"AVG\"\n",
    "\n",
    "        if date_type == \"text\":\n",
    "            sql_query = (\n",
    "                f\"\"\"\n",
    "                SELECT DATE(`{x_axis}`) AS `{x_axis}`,\n",
    "                    {operation}(`{y_axis}`) AS `{y_axis}`, `{group_by}`\n",
    "                FROM `{self.table}`\"\"\"\n",
    "                + clause\n",
    "                + f\"\"\"\n",
    "                GROUP BY `{group_by}`, DATE(`{x_axis}`)\n",
    "                ORDER BY DATE(`{x_axis}`) ASC\n",
    "            \"\"\"\n",
    "            )\n",
    "\n",
    "        elif date_type in [\"int\", \"bigint\", \"integer\"]:\n",
    "            sql_query = (\n",
    "                f\"\"\"\n",
    "                SELECT `{x_axis}` AS `{x_axis}`,\n",
    "                    {operation}(`{y_axis}`) AS `{y_axis}`,\n",
    "                    `{group_by}`\n",
    "                FROM `{self.table}`\"\"\"\n",
    "                + clause\n",
    "                + f\"\"\"\n",
    "                GROUP BY `{group_by}`, `{x_axis}`\n",
    "                ORDER BY `{x_axis}` ASC\n",
    "            \"\"\"\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            sql_query = (\n",
    "                f\"\"\"\n",
    "                SELECT `{x_axis}` AS `{x_axis}`,\n",
    "                    {operation}(`{y_axis}`) AS `{y_axis}`, {group_by}\n",
    "                FROM `{self.table}`\"\"\"\n",
    "                + clause\n",
    "                + f\"\"\"\n",
    "                GROUP BY `{group_by}`, {x_axis}\n",
    "                ORDER BY `{x_axis}` ASC\n",
    "            \"\"\"\n",
    "            )\n",
    "        sql_query = sql_query.replace('\"', \"`\")\n",
    " \n",
    "        \n",
    "\n",
    "        return pd.read_sql(text(sql_query), self.connection)\n",
    "\n",
    "    def _get_derived_result(self):\n",
    "        \"\"\"\n",
    "        Gives an output for derived results\n",
    "        \"\"\"\n",
    "        x_axis, y_axis, binning, operation, group_by = self._extract_chart_config()\n",
    "        derived = self.derived\n",
    "        if operation == \"\" or operation == \"mean\" or operation == None:\n",
    "            operation = \"AVG\"\n",
    "        # need to think of ways to not restrict derived , it may even be used for x - axis\n",
    "        # use derived to get the chart_config\n",
    "        query = f\"\"\"\n",
    "        SELECT `{x_axis}`, {operation}({derived[\"formula\"]}) as `{derived[\"term\"]}` \n",
    "        FROM `{self.table}`\n",
    "        GROUP BY `{x_axis}`\n",
    "        ORDER BY `{x_axis}` ASC\n",
    "        \"\"\"\n",
    "        df = pd.read_sql(text(query), self.connection)\n",
    "        if binning == \"\" or binning==\"monthly\" :\n",
    "            date_range = df[x_axis].dt.date.max() - df[x_axis].dt.date.min()\n",
    "            print(f\"date range is: {date_range.days}\")\n",
    "            if date_range.days < 30:\n",
    "                binning = \"daily\"\n",
    "            elif date_range.days > 1460:\n",
    "                binning = \"yearly\"\n",
    "            else:\n",
    "                binning = \"monthly\"\n",
    "\n",
    "        df[x_axis] = df[x_axis].dt.to_period(self.freq_dict[binning])\n",
    "        if operation == None or operation == \"\" or operation == 'AVG':\n",
    "            operation = \"mean\"\n",
    "        df = df.groupby(x_axis)[derived[\"term\"]].agg(operation).reset_index()\n",
    "        return df\n",
    "\n",
    "    def _generate_relation_resultant_df(self):\n",
    "        x_axis, y_axis, binning, operation, group_by,formula = self._extract_chart_config()\n",
    "        query = f'''\n",
    "        SELECT `{x_axis}`,{y_axis} from `{self.table}`\n",
    "        '''\n",
    "        return pd.read_sql(text(query),self.connection)\n",
    "    def _generate_distribution_resultant_df(self):\n",
    "        x_axis, y_axis, binning, operation, group_by,formula = self._extract_chart_config()\n",
    "        col_data_type = self._get_column_data_types(x_axis)\n",
    "        data_type = col_data_type.loc[col_data_type[\"column_name\".upper()] == x_axis, \"data_type\".upper()].values[0]\n",
    "        print(data_type)\n",
    "        if data_type.lower() in ['double','bigint']:\n",
    "            \n",
    "            query = f'''\n",
    "            SELECT `{x_axis}` from `{self.table}`\n",
    "            '''\n",
    "            df =  pd.read_sql(text(query),self.connection)\n",
    "            Q1 = np.percentile(df[x_axis], 25)\n",
    "            Q3 = np.percentile(df[x_axis], 75)\n",
    "            IQR = Q3 - Q1\n",
    "            \n",
    "            # Calculate the bin width using the Freedman-Diaconis rule\n",
    "            bin_width = 2 * IQR / (df.shape[0] ** (1/3))\n",
    "            bin_width = max(2,bin_width)\n",
    "            # Calculate the number of bins\n",
    "            num_bins = int((df[x_axis].max() - df[x_axis].min()) / bin_width)\n",
    "            \n",
    "            # Create the bins and calculate frequencies\n",
    "            freq, bins = np.histogram(df[x_axis], bins=num_bins)\n",
    "            \n",
    "            # Create a DataFrame with the bins and frequencies\n",
    "            bins_midpoints = 0.5 * (bins[:-1] + bins[1:])  # Calculate midpoints of bins for better representation\n",
    "            df_bins = pd.DataFrame({\n",
    "                'Bin_Start': bins[:-1],\n",
    "                'Bin_End': bins[1:],\n",
    "                'Frequency': freq,\n",
    "                'Midpoint': bins_midpoints\n",
    "            })\n",
    "            return df_bins\n",
    "        else:\n",
    "            query = f'''\n",
    "            SELECT {x_axis},COUNT(`{x_axis}`) from `{self.table}` GROUP BY `{x_axis}`\n",
    "            '''\n",
    "            df=  pd.read_sql(text(query),self.connection)\n",
    "            return df\n",
    "            \n",
    "    def _extract_chart_config(self):\n",
    "        \"\"\"\n",
    "        Extracts chart configuration parameters for MySQL.\n",
    "        \"\"\"\n",
    "        x_axis = self.chart_config.get(\"x_axis\", \"\")\n",
    "        y_axis = self.chart_config.get(\"y_axis\", \"\")\n",
    "        if \" \" in y_axis:\n",
    "            y_axis = '`'+y_axis+'`'\n",
    "        binning = self.chart_config.get(\"binning\", \"\")\n",
    "        operation = self.chart_config.get(\"operation\", \"\")\n",
    "        formula = self.chart_config.get(\"formula\",\"\")\n",
    "        if operation == \"\" or operation == \"mean\":\n",
    "            operation = \"AVG\"\n",
    "        group_by = self.chart_config.get(\"group_by\", \"\")\n",
    "        return x_axis, y_axis, binning, operation, group_by,formula\n",
    "\n",
    "    def generate_resultant_df(self, metric_type):\n",
    "        \"\"\"\n",
    "        Public method to generate a pandas DataFrame based on the chart configuration for MySQL.\n",
    "        \"\"\"\n",
    "        print(\"metric_type: \",metric_type)\n",
    "        \n",
    "        if metric_type == \"combination\":\n",
    "            return self._generate_combination_resultant_df()\n",
    "        elif metric_type in [\n",
    "            \"group_aggregate\",\n",
    "            \"group_aggregates\",\n",
    "            \"group_aggregation\",\n",
    "        ]:\n",
    "            return self._generate_groupaggregate_resultant_df()\n",
    "        elif metric_type == \"time_series\":\n",
    "            return self._generate_timeseries_resultant_df()\n",
    "        elif metric_type == \"multilevel_categorical\":\n",
    "            return self._generate_multilevelcategorical_resultant_df()\n",
    "        elif metric_type == \"relational\":\n",
    "            return self._generate_relation_resultant_df()\n",
    "        elif metric_type == \"distribution\":\n",
    "            return self._generate_distribution_resultant_df()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid metric type provided.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3820d69-f8e6-4608-907d-b91e4ec03534",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_order_value = '''\n",
    "average_order_value\n",
    "Definition : Average order value (AOV) tracks the average dollar amount spent each time a customer places an order on a website or mobile app. To calculate your companyâ€™s average order value, simply divide total revenue by the number of orders.\n",
    "Formula : Revenue/Number of orders\n",
    "'''\n",
    "gross_profit_margin = '''\n",
    "gross_profit_margin\n",
    "Definition: Measures the profitability of a company after subtracting the cost of goods sold (COGS).\n",
    "Formula:GrossÂ ProfitÂ Margin=((Revenueâˆ’COGS)/Revenue)Ã—100\n",
    "'''\n",
    "return_on_investment = '''\n",
    "return_on_investment\n",
    "Definition:Measures the profitability of an investment.\n",
    "Formula:ROI=((NetÂ ProfitÂ fromÂ Investmentâˆ’CostÂ ofÂ Investment)/CostÂ ofÂ Investment)Ã—100\n",
    "'''\n",
    "customer_acquistion_cost = '''\n",
    "customer_acquistion_cost\n",
    "Definition:Measures the cost of acquiring a new customer.\n",
    "formulae: NumberÂ ofÂ NewÂ CustomersÂ Acquired/TotalÂ SalesÂ andÂ MarketingÂ Expenses\n",
    "'''\n",
    "customer_lifetime_value ='''\n",
    "customer_lifetime_value\n",
    "Definition:Measures the total revenue a business can expect from a single customer account.\n",
    "formulae: AverageÂ PurchaseÂ ValueÃ—AverageÂ PurchaseÂ FrequencyÃ—AverageÂ CustomerÂ Lifespan \n",
    "'''\n",
    "sales_growth = '''\n",
    "Sales Growth\n",
    "Definition: Measures the increase in sales over a specific period.\n",
    "formulae:SalesÂ Growth=((SalesÂ inÂ CurrentÂ Periodâˆ’SalesÂ inÂ PreviousÂ Period)/SalesÂ inÂ PreviousÂ Period)Ã—100\n",
    "'''\n",
    "customer_satisfaction_score = '''\n",
    "customer satisfaction_score\n",
    "Definition: Measures customer satisfaction with a product or service.\n",
    "Formula: ( NumberÂ ofÂ SurveyÂ Responses/NumberÂ ofÂ SatisfiedÂ Customers)Ã—100\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "624a2dd9-6275-4c52-9acc-cbdcb159908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_trend ='''\n",
    "time_series: Analyzing time series trends. Graph type: Line.\n",
    "Example: 1.\"Give me sales trend.\"\n",
    "         2.\"Sales from July to october\"\n",
    "chart types supported : line\n",
    "'''\n",
    "group_aggregates = '''\n",
    "group_aggregates: Analyzing over different product categories. Graph types: Bar, Pie,stacked_bar\n",
    "Example:1. \"Give me sales for each product category.\"\n",
    "        2. \"Give me sales for product category A and Product category B\"\n",
    "        3. Give me count per product category\n",
    "chart types supported: bar, pie\n",
    "'''\n",
    "combination = '''\n",
    "combination: A combination of time_series and group_aggregates.Where query is requoring Analysis of time series trends for each group category. Graph type: multiline.\n",
    "Example: 1.Give me product wise sales trend ,\n",
    "         2. sales trend for each vehicle_type\n",
    "chart types supported: multiline\n",
    "'''\n",
    "multilevel_categorical = '''\n",
    "multilevel_categorical: Analyze trend where there is a split at 2 levels\n",
    "Example: 1. Show me the quantity sold by Product category breakdown by gender\n",
    "        2. Show me the average profits generated by each product category segmented by customer login type\n",
    "chart types supported: group_bar, stacked_bar\n",
    "'''\n",
    "relational ='''\n",
    "relational: Analyze relationships like correlation and distribution between two or more columns\n",
    "Example: 1. relationship between sales and profit \n",
    "        2. correlation across marketting expenditure and profits\n",
    "chart types supported: correlogram, scatter plot\n",
    "'''\n",
    "distribution = '''\n",
    "distribution: chart types which highlight the distribution trend for a variable\n",
    "Example: 1. show me the distribution of age across the organization\n",
    "        2. Highlight the skewness of in quantity sold \n",
    "chart types supported: histogram,box plot\n",
    "Note y_axis would be None in this case always\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8d21466-1fbe-483f-9b82-f0eca6157ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_hints = [time_series_trend,group_aggregates,combination,multilevel_categorical,relational,distribution]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e3213cc-7e26-43f4-8ce5-f76f5ff44e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_hints = FAISS.from_texts(chart_hints,embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7665dd29-2e81-423a-be9b-c8ab235e3f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_glossary = [average_order_value,gross_profit_margin,return_on_investment,customer_acquistion_cost,customer_lifetime_value,sales_growth,customer_satisfaction_score]\n",
    "knowledge_hints = FAISS.from_texts(knowledge_glossary,embedding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e12de427-b0c6-448a-b585-7d693a2a5f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata =metadata.values.tolist()\n",
    "metadata = [str(i) for i in metadata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dca6761f-91e5-4798-9d37-c59e50ffa3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['auto_insurance', 'Customer', 'text']\",\n",
       " \"['auto_insurance', 'State', 'text']\",\n",
       " \"['auto_insurance', 'Customer Lifetime Value', 'double']\",\n",
       " \"['auto_insurance', 'Response', 'text']\",\n",
       " \"['auto_insurance', 'Coverage', 'text']\",\n",
       " \"['auto_insurance', 'Education', 'text']\",\n",
       " \"['auto_insurance', 'Effective To Date', 'datetime']\",\n",
       " \"['auto_insurance', 'EmploymentStatus', 'text']\",\n",
       " \"['auto_insurance', 'Gender', 'text']\",\n",
       " \"['auto_insurance', 'Income', 'bigint']\",\n",
       " \"['auto_insurance', 'Location Code', 'text']\",\n",
       " \"['auto_insurance', 'Marital Status', 'text']\",\n",
       " \"['auto_insurance', 'Monthly Premium Auto', 'bigint']\",\n",
       " \"['auto_insurance', 'Months Since Last Claim', 'bigint']\",\n",
       " \"['auto_insurance', 'Months Since Policy Inception', 'bigint']\",\n",
       " \"['auto_insurance', 'Number of Open Complaints', 'bigint']\",\n",
       " \"['auto_insurance', 'Number of Policies', 'bigint']\",\n",
       " \"['auto_insurance', 'Policy Type', 'text']\",\n",
       " \"['auto_insurance', 'Policy', 'text']\",\n",
       " \"['auto_insurance', 'Renew Offer Type', 'text']\",\n",
       " \"['auto_insurance', 'Sales Channel', 'text']\",\n",
       " \"['auto_insurance', 'Total Claim Amount', 'double']\",\n",
       " \"['auto_insurance', 'Vehicle Class', 'text']\",\n",
       " \"['auto_insurance', 'Vehicle Size', 'text']\",\n",
       " \"['bank_acc', 'user', 'bigint']\",\n",
       " \"['bank_acc', 'default', 'text']\",\n",
       " \"['bank_acc', 'balance', 'bigint']\",\n",
       " \"['bank_acc', 'housing', 'text']\",\n",
       " \"['bank_acc', 'loan', 'text']\",\n",
       " \"['bank_comms', 'user_id', 'bigint']\",\n",
       " \"['bank_comms', 'campaign', 'bigint']\",\n",
       " \"['bank_comms', 'pdays', 'bigint']\",\n",
       " \"['bank_comms', 'previous', 'bigint']\",\n",
       " \"['bank_comms', 'poutcome', 'text']\",\n",
       " \"['bank_comms', 'contact mode', 'text']\",\n",
       " \"['bank_comms', 'contact day', 'bigint']\",\n",
       " \"['bank_comms', 'contact month', 'text']\",\n",
       " \"['bank_comms', 'contact duration', 'bigint']\",\n",
       " \"['bank_comms', 'deposit', 'text']\",\n",
       " \"['bank_demog', 'id', 'bigint']\",\n",
       " \"['bank_demog', 'age', 'bigint']\",\n",
       " \"['bank_demog', 'job', 'text']\",\n",
       " \"['bank_demog', 'marital', 'text']\",\n",
       " \"['bank_demog', 'education', 'text']\",\n",
       " \"['bank_demog', 'gender', 'text']\",\n",
       " \"['bike_rentals', 'instant', 'bigint']\",\n",
       " \"['bike_rentals', 'dteday', 'datetime']\",\n",
       " \"['bike_rentals', 'season', 'bigint']\",\n",
       " \"['bike_rentals', 'yr', 'bigint']\",\n",
       " \"['bike_rentals', 'mnth', 'bigint']\",\n",
       " \"['bike_rentals', 'holiday', 'bigint']\",\n",
       " \"['bike_rentals', 'weekday', 'bigint']\",\n",
       " \"['bike_rentals', 'workingday', 'bigint']\",\n",
       " \"['bike_rentals', 'weathersit', 'bigint']\",\n",
       " \"['bike_rentals', 'temp', 'double']\",\n",
       " \"['bike_rentals', 'atemp', 'double']\",\n",
       " \"['bike_rentals', 'hum', 'double']\",\n",
       " \"['bike_rentals', 'windspeed', 'double']\",\n",
       " \"['bike_rentals', 'casual', 'bigint']\",\n",
       " \"['bike_rentals', 'registered', 'bigint']\",\n",
       " \"['bike_rentals', 'cnt', 'bigint']\",\n",
       " \"['cgr_premiums', 'territory', 'bigint']\",\n",
       " \"['cgr_premiums', 'gender', 'text']\",\n",
       " \"['cgr_premiums', 'birthdate', 'datetime']\",\n",
       " \"['cgr_premiums', 'ypc', 'bigint']\",\n",
       " \"['cgr_premiums', 'current_premium', 'double']\",\n",
       " \"['cgr_premiums', 'indicated_premium', 'double']\",\n",
       " \"['cgr_premiums', 'selected_premium', 'double']\",\n",
       " \"['cgr_premiums', 'underlying_premium', 'double']\",\n",
       " \"['cgr_premiums', 'fixed_expenses', 'double']\",\n",
       " \"['cgr_premiums', 'underlying_total_premium', 'double']\",\n",
       " \"['cgr_premiums', 'cgr_factor', 'double']\",\n",
       " \"['cgr_premiums', 'cgr', 'text']\",\n",
       " \"['customer_support', 'Unnamed: 0', 'bigint']\",\n",
       " \"['customer_support', 'Ticket ID', 'double']\",\n",
       " \"['customer_support', 'Customer Name', 'text']\",\n",
       " \"['customer_support', 'Customer Email', 'text']\",\n",
       " \"['customer_support', 'Customer Age', 'bigint']\",\n",
       " \"['customer_support', 'Customer Gender', 'text']\",\n",
       " \"['customer_support', 'Product Purchased', 'text']\",\n",
       " \"['customer_support', 'Date of Purchase', 'datetime']\",\n",
       " \"['customer_support', 'Ticket Type', 'text']\",\n",
       " \"['customer_support', 'Ticket Subject', 'text']\",\n",
       " \"['customer_support', 'Ticket Description', 'text']\",\n",
       " \"['customer_support', 'Ticket Status', 'text']\",\n",
       " \"['customer_support', 'Ticket Priority', 'text']\",\n",
       " \"['customer_support', 'Ticket Channel', 'text']\",\n",
       " \"['customer_support', 'Customer Satisfaction Rating', 'double']\",\n",
       " \"['dress', 'Dress_ID', 'bigint']\",\n",
       " \"['dress', 'Style', 'text']\",\n",
       " \"['dress', 'Price', 'text']\",\n",
       " \"['dress', 'Rating', 'double']\",\n",
       " \"['dress', 'Size', 'text']\",\n",
       " \"['dress', 'Season', 'text']\",\n",
       " \"['dress', 'NeckLine', 'text']\",\n",
       " \"['dress', 'SleeveLength', 'text']\",\n",
       " \"['dress', 'Material', 'text']\",\n",
       " \"['dress', 'FabricType', 'text']\",\n",
       " \"['dress', 'Decoration', 'text']\",\n",
       " \"['dress', 'Pattern Type', 'text']\",\n",
       " \"['dress', 'Recommendation', 'bigint']\",\n",
       " \"['ecom_product', 'Product ID', 'text']\",\n",
       " \"['ecom_product', 'Product Name', 'text']\",\n",
       " \"['ecom_product', 'Category', 'text']\",\n",
       " \"['ecom_sales', 'Order_Date', 'datetime']\",\n",
       " \"['ecom_sales', 'Time', 'text']\",\n",
       " \"['ecom_sales', 'Delivery days', 'double']\",\n",
       " \"['ecom_sales', 'Customer_Id', 'bigint']\",\n",
       " \"['ecom_sales', 'Device_Type', 'text']\",\n",
       " \"['ecom_sales', 'Customer_Login_type', 'text']\",\n",
       " \"['ecom_sales', 'Product ID', 'text']\",\n",
       " \"['ecom_sales', 'Sales', 'double']\",\n",
       " \"['ecom_sales', 'Quantity', 'double']\",\n",
       " \"['ecom_sales', 'Discount', 'double']\",\n",
       " \"['ecom_sales', 'Profit', 'double']\",\n",
       " \"['ecom_sales', 'Shipping_Cost', 'double']\",\n",
       " \"['ecom_sales', 'Order_Priority', 'text']\",\n",
       " \"['ecom_sales', 'Payment_method', 'text']\",\n",
       " \"['ecommerce', 'Order_Date', 'datetime']\",\n",
       " \"['ecommerce', 'Time', 'text']\",\n",
       " \"['ecommerce', 'Aging', 'double']\",\n",
       " \"['ecommerce', 'Customer_Id', 'bigint']\",\n",
       " \"['ecommerce', 'Gender', 'text']\",\n",
       " \"['ecommerce', 'Device_Type', 'text']\",\n",
       " \"['ecommerce', 'Customer_Login_type', 'text']\",\n",
       " \"['ecommerce', 'Product_Category', 'text']\",\n",
       " \"['ecommerce', 'Product', 'text']\",\n",
       " \"['ecommerce', 'Sales', 'double']\",\n",
       " \"['ecommerce', 'Quantity', 'double']\",\n",
       " \"['ecommerce', 'Discount', 'double']\",\n",
       " \"['ecommerce', 'Profit', 'double']\",\n",
       " \"['ecommerce', 'Shipping_Cost', 'double']\",\n",
       " \"['ecommerce', 'Order_Priority', 'text']\",\n",
       " \"['ecommerce', 'Payment_method', 'text']\",\n",
       " \"['flag_data', 'responseid', 'double']\",\n",
       " \"['flag_data', 'Increase_Usage_Enablex_Samples', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_Enablex_Rep_Visits', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_Enablex_Additional_Clinical_Data_Treatment_OAB', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_Enablex_Additional_Clinical_Data_Side_Effects', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_Enablex_Better_Managed_Care_Coverage', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_Enablex_Better_Medicare_Part_D_Coverage', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_Enablex_More_Info_Managed_Care', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_Enablex_More_Support_Manufacturer_Lower_Cost', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_Enablex_No_Factors_Influence', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_Myrbetriq_Samples', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_Myrbetriq_Rep_Visits', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_Myrbetriq_Additional_Clinical_Data_Treatment_OAB', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_Myrbetriq_Additional_Clinical_Data_Side_Effects', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_Myrbetriq_Better_Managed_Care_Coverage', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_Myrbetriq_Better_Medicare_Part_D_Coverage', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_Myrbetriq_More_Info_Managed_Care', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_Myrbetriq_More_Support_Manufacturer_Lower_Cost', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_Myrbetriq_No_Factors_Influence', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_VESIcare_Samples', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_VESIcare_Rep_Visits', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_VESIcare_Additional_Clinical_Data_Treatment_OAB', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_VESIcare_Additional_Clinical_Data_Side_Effects', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_VESIcare_Better_Managed_Care_Coverage', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_VESIcare_Better_Medicare_Part_D_Coverage', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_VESIcare_More_Info_Managed_Care', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_VESIcare_More_Support_Manufacturer_Lower_Cost', 'bigint']\",\n",
       " \"['flag_data', 'Increase_Usage_VESIcare_No_Factors_Influence', 'bigint']\",\n",
       " \"['flag_data', 'Pharmacy_Call_Back_Reasons_Enablex_High_Out_of_Pocket_Cost', 'bigint']\",\n",
       " \"['flag_data', 'Pharmacy_Call_Back_Reasons_Enablex_Poor_Commercial_Coverage', 'bigint']\",\n",
       " \"['flag_data', 'Pharmacy_Call_Back_Reasons_Enablex_Poor_Medicare_Coverage', 'bigint']\",\n",
       " \"['flag_data', 'Pharmacy_Call_Back_Reasons_Enablex_Side_Effect_Concerns', 'bigint']\",\n",
       " \"['flag_data', 'Pharmacy_Call_Back_Reasons_Enablex_Other_Specify', 'bigint']\",\n",
       " \"['flag_data', 'Pharmacy_Call_Back_Reasons_Myrbetriq_High_Out_of_Pocket_Cost', 'bigint']\",\n",
       " \"['flag_data', 'Pharmacy_Call_Back_Reasons_Myrbetriq_Poor_Commercial_Coverage', 'bigint']\",\n",
       " \"['flag_data', 'Pharmacy_Call_Back_Reasons_Myrbetriq_Poor_Medicare_Coverage', 'bigint']\",\n",
       " \"['flag_data', 'Pharmacy_Call_Back_Reasons_Myrbetriq_Side_Effect_Concerns', 'bigint']\",\n",
       " \"['flag_data', 'Pharmacy_Call_Back_Reasons_Myrbetriq_Other_Specify', 'bigint']\",\n",
       " \"['flag_data', 'Pharmacy_Call_Back_Reasons_VESIcare_High_Out_of_Pocket_Cost', 'bigint']\",\n",
       " \"['flag_data', 'Pharmacy_Call_Back_Reasons_VESIcare_Poor_Commercial_Coverage', 'bigint']\",\n",
       " \"['flag_data', 'Pharmacy_Call_Back_Reasons_VESIcare_Poor_Medicare_Coverage', 'bigint']\",\n",
       " \"['flag_data', 'Pharmacy_Call_Back_Reasons_VESIcare_Side_Effect_Concerns', 'bigint']\",\n",
       " \"['generic_percentage_data', 'responseid', 'double']\",\n",
       " \"['generic_percentage_data', 'qid', 'double']\",\n",
       " \"['generic_percentage_data', 'starttime', 'text']\",\n",
       " \"['generic_percentage_data', 'endtime', 'text']\",\n",
       " \"['generic_percentage_data', 'srispecialty', 'text']\",\n",
       " \"['generic_percentage_data', 'pdrp', 'text']\",\n",
       " \"['generic_percentage_data', 'sixmonth1hdecile', 'bigint']\",\n",
       " \"['generic_percentage_data', 'sixmonth2hdecile', 'bigint']\",\n",
       " \"['generic_percentage_data', 'Detrol LA / tolterodine ER (Percentage of OAB Patients)', 'double']\",\n",
       " \"['generic_percentage_data', 'Enablex (darifenacin) (Percentage of OAB Patients)', 'double']\",\n",
       " \"['generic_percentage_data', 'Myrbetriq (mirabegron) (Percentage of OAB Patients)', 'double']\",\n",
       " \"['generic_percentage_data', 'Toviaz (fesoterodine) (Percentage of OAB Patients)', 'double']\",\n",
       " \"['generic_percentage_data', 'VESIcare (solifenacin) (Percentage of OAB Patients)', 'double']\",\n",
       " \"['generic_percentage_data', 'Ditropan XL / oxybutynin ER (Percentage of OAB Patients)', 'double']\",\n",
       " \"['generic_percentage_data', 'Gelnique (3% or 10%) (Percentage of OAB Patients)', 'double']\",\n",
       " \"['generic_percentage_data', 'Sanctura / tropsium (Percentage of OAB Patients)', 'double']\",\n",
       " \"['generic_percentage_data', 'Sanctura XR / tropsium ER (Percentage of OAB Patients)', 'double']\",\n",
       " \"['generic_percentage_data', 'Oxytrol / Oxytrol for Women (Percentage of OAB Patients)', 'double']\",\n",
       " \"['generic_percentage_data', 'Other (Percentage of OAB Patients)', 'double']\",\n",
       " \"['generic_percentage_data', 'Enablex (darifenacin) (Number of Times Visited by Rep)', 'double']\",\n",
       " \"['generic_percentage_data', 'Myrbetriq (mirabegron) (Number of Times Visited by Rep)', 'double']\",\n",
       " \"['generic_percentage_data', 'VESIcare (solifenacin) (Number of Times Visited by Rep)', 'double']\",\n",
       " \"['generic_percentage_data', 'Enablex (darifenacin) (Generic Switch %)', 'double']\",\n",
       " \"['generic_percentage_data', 'Myrbetriq (mirabegron) (Generic Switch %)', 'double']\",\n",
       " \"['generic_percentage_data', 'VESIcare (solifenacin) (Generic Switch %)', 'double']\",\n",
       " \"['generic_percentage_data', 'Enablex (darifenacin) (Call-back %)', 'double']\",\n",
       " \"['generic_percentage_data', 'Myrbetriq (mirabegron) (Call-back %)', 'double']\",\n",
       " \"['generic_percentage_data', 'VESIcare (solifenacin) (Call-back %)', 'double']\",\n",
       " \"['generic_percentage_data', 'Medicare Advantage Plan (Part C) (%)', 'double']\",\n",
       " \"['generic_percentage_data', 'Medicare Prescription Drug Plan (Part D) (%)', 'double']\",\n",
       " \"['generic_percentage_data', 'Medicaid / Managed Medicaid (%)', 'double']\",\n",
       " \"['generic_percentage_data', 'Commercial Coverage (HMO, PPO, POS) (%)', 'double']\",\n",
       " \"['generic_percentage_data', 'Traditional Indemnity / Fee-for-Service (%)', 'double']\",\n",
       " \"['generic_percentage_data', 'No Coverage / Out-of-pocket (%)', 'double']\",\n",
       " \"['generic_percentage_data', 'Other (Please specify) (Percent of Patients)', 'double']\",\n",
       " \"['generic_percentage_data', 'tier', 'text']\",\n",
       " \"['generic_percentage_data', 'segment', 'text']\",\n",
       " \"['generic_percentage_data', 'tierquota', 'text']\",\n",
       " \"['generic_percentage_data', 'qs1', 'text']\",\n",
       " \"['generic_percentage_data', 'qs2', 'double']\",\n",
       " \"['generic_percentage_data', 'qs3', 'text']\",\n",
       " \"['generic_percentage_data', 'qs3a', 'text']\",\n",
       " \"['generic_percentage_data', 'qs4', 'double']\",\n",
       " \"['generic_percentage_data', 'Detrol_LA_Change_Rx_12m_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'Enablex_Change_Rx_12m_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'Myrbetriq_Change_Rx_12m_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'Toviaz_Change_Rx_12m_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'VESIcare_Change_Rx_12m_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'Patients_Switch_Request_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'Grant_Switch_Request_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'Managed_Care_Impact_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'Sales_Rep_Impact_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'QTC_Safety_Importance_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'CNS_Safety_Importance_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'Prescribe_New_OAB_Meds_Soon_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'Concerns_Branded_Side_Effects_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'Branded_Superior_To_Generics_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'Cost_To_Patient_Importance_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'Pharmacy_Call_Backs_Importance_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'OAB_Meds_Interchangeable_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'No_Efficacy_Diff_Brand_Generic_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'Prescribe_Sample_Cabinet_Meds_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'Prescriptions_Driven_By_Requests_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'Patients_Donâ€™t_Know_Brands_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'Prescribe_Generic_First_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'Copay_Cards_Importance_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'Detrol_LA_Preference_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'Enablex_Preference_1_least_7_good', 'double']\",\n",
       " \"['generic_percentage_data', 'Myrbetriq_Preference_1_least_7_good', 'double']\",\n",
       " \"['generic_percentage_data', 'Toviaz_Preference_1_least_7_good', 'bigint']\",\n",
       " \"['generic_percentage_data', 'VESIcare_Preference_1_least_7_good', 'bigint']\",\n",
       " \"['interest_rate', 'DATE', 'datetime']\",\n",
       " \"['interest_rate', 'DFF', 'double']\",\n",
       " \"['payroll', 'DATE', 'datetime']\",\n",
       " \"['payroll', 'NPPTTL', 'double']\",\n",
       " \"['rank_data', 'responseid', 'double']\",\n",
       " \"['rank_data', 'VESIcare (solifenacin) barriers to prescribing Rank 1', 'text']\",\n",
       " \"['rank_data', 'VESIcare (solifenacin) barriers to prescribing Rank 2', 'text']\",\n",
       " \"['rank_data', 'VESIcare (solifenacin) barriers to prescribing Rank 3', 'text']\",\n",
       " \"['rank_data', 'VESIcare (solifenacin) barriers to prescribing Rank 4', 'text']\",\n",
       " \"['rank_data', 'VESIcare (solifenacin) barriers to prescribing Rank 5', 'text']\",\n",
       " \"['rank_data', 'Enablex (darifenacin) 5 reasons for prescribing Rank 1', 'text']\",\n",
       " \"['rank_data', 'Enablex (darifenacin) 5 reasons for prescribing Rank 2', 'text']\",\n",
       " \"['rank_data', 'Enablex (darifenacin) 5 reasons for prescribing Rank 3', 'text']\",\n",
       " \"['rank_data', 'Enablex (darifenacin) 5 reasons for prescribing Rank 4', 'text']\",\n",
       " \"['rank_data', 'Enablex (darifenacin) 5 reasons for prescribing Rank 5', 'text']\",\n",
       " \"['rank_data', 'Myrbetriq (mirabegron)Rank reasons for prescribing Rank 1', 'text']\",\n",
       " \"['rank_data', 'Myrbetriq (mirabegron)Rank reasons for prescribing Rank 2', 'text']\",\n",
       " \"['rank_data', 'Myrbetriq (mirabegron)Rank reasons for prescribing Rank 3', 'text']\",\n",
       " \"['rank_data', 'Myrbetriq (mirabegron)Rank reasons for prescribing Rank 4', 'text']\",\n",
       " \"['rank_data', 'Myrbetriq (mirabegron)Rank reasons for prescribing Rank 5', 'text']\",\n",
       " \"['rank_data', ' VESIcare (solifenacin)  reasons for prescribing Rank 1', 'text']\",\n",
       " \"['rank_data', ' VESIcare (solifenacin)  reasons for prescribing Rank 2', 'text']\",\n",
       " \"['rank_data', ' VESIcare (solifenacin)  reasons for prescribing Rank 3', 'text']\",\n",
       " \"['rank_data', ' VESIcare (solifenacin)  reasons for prescribing Rank 4', 'text']\",\n",
       " \"['rank_data', ' VESIcare (solifenacin)  reasons for prescribing Rank 5', 'text']\",\n",
       " \"['rank_data', 'Enablex (darifenacin) barriers to prescribing Rank 1', 'text']\",\n",
       " \"['rank_data', 'Enablex (darifenacin) barriers to prescribing Rank 2', 'text']\",\n",
       " \"['rank_data', 'Enablex (darifenacin) barriers to prescribing Rank 3', 'text']\",\n",
       " \"['rank_data', 'Enablex (darifenacin) barriers to prescribing Rank 4', 'text']\",\n",
       " \"['rank_data', 'Enablex (darifenacin) barriers to prescribing Rank 5', 'text']\",\n",
       " \"['rank_data', ' Myrbetriq (mirabegron) barriers to prescribing Rank 1', 'text']\",\n",
       " \"['rank_data', ' Myrbetriq (mirabegron) barriers to prescribing Rank 2', 'text']\",\n",
       " \"['rank_data', ' Myrbetriq (mirabegron) barriers to prescribing Rank 3', 'text']\",\n",
       " \"['rank_data', ' Myrbetriq (mirabegron) barriers to prescribing Rank 4', 'text']\",\n",
       " \"['rank_data', ' Myrbetriq (mirabegron) barriers to prescribing Rank 5', 'text']\",\n",
       " \"['rank_data', ' Myrbetriq (mirabegron)  Increase in Use Rank 1', 'text']\",\n",
       " \"['rank_data', ' Myrbetriq (mirabegron)  Increase in Use Rank 2', 'text']\",\n",
       " \"['rank_data', ' Myrbetriq (mirabegron)  Increase in Use Rank 3', 'text']\",\n",
       " \"['rank_data', ' Myrbetriq (mirabegron)  Increase in Use Rank 4', 'text']\",\n",
       " \"['rank_data', ' Myrbetriq (mirabegron)  Increase in Use Rank 5', 'text']\",\n",
       " \"['rank_data', ' VESIcare (solifenacin)  Increase in Use Rank 1', 'text']\",\n",
       " \"['rank_data', ' VESIcare (solifenacin)  Increase in Use Rank 2', 'text']\",\n",
       " \"['rank_data', ' VESIcare (solifenacin)  Increase in Use Rank 3', 'text']\",\n",
       " \"['rank_data', ' VESIcare (solifenacin)  Increase in Use Rank 4', 'text']\",\n",
       " \"['rank_data', ' VESIcare (solifenacin)  Increase in Use Rank 5', 'text']\",\n",
       " \"['rank_data', 'Enablex (darifenacin)  Decrease in Use Rank 1', 'text']\",\n",
       " \"['rank_data', 'Enablex (darifenacin)  Decrease in Use Rank 2', 'text']\",\n",
       " \"['rank_data', 'Enablex (darifenacin)  Decrease in Use Rank 3', 'text']\",\n",
       " \"['rank_data', 'Enablex (darifenacin)  Decrease in Use Rank 4', 'text']\",\n",
       " \"['rank_data', 'Enablex (darifenacin)  Decrease in Use Rank 5', 'text']\",\n",
       " \"['rank_data', 'VESIcare (solifenacin) Increase in Use Rank 1', 'text']\",\n",
       " \"['rank_data', 'VESIcare (solifenacin) Increase in Use Rank 2', 'text']\",\n",
       " \"['rank_data', 'VESIcare (solifenacin) Increase in Use Rank 3', 'text']\",\n",
       " \"['rank_data', 'VESIcare (solifenacin) Increase in Use Rank 4', 'text']\",\n",
       " \"['rank_data', 'VESIcare (solifenacin) Increase in Use Rank 5', 'text']\",\n",
       " \"['sri_dataset', 'responseid', 'double']\",\n",
       " \"['sri_dataset', 'qid', 'double']\",\n",
       " \"['sri_dataset', 'starttime', 'text']\",\n",
       " \"['sri_dataset', 'endtime', 'text']\",\n",
       " \"['sri_dataset', 'imsid', 'bigint']\",\n",
       " \"['sri_dataset', 'srispecialty', 'text']\",\n",
       " \"['sri_dataset', 'pdrp', 'text']\",\n",
       " \"['sri_dataset', 'sixmonth1hdecile', 'bigint']\",\n",
       " \"['sri_dataset', 'sixmonth2hdecile', 'bigint']\",\n",
       " \"['sri_dataset', 'tier', 'text']\",\n",
       " \"['sri_dataset', 'segment', 'text']\",\n",
       " \"['sri_dataset', 'quotaquestion', 'text']\",\n",
       " \"['sri_dataset', 'tierquota', 'text']\",\n",
       " \"['sri_dataset', 'qs1', 'text']\",\n",
       " \"['sri_dataset', 'qs1_other', 'double']\",\n",
       " \"['sri_dataset', 'qs2', 'double']\",\n",
       " \"['sri_dataset', 'qs3', 'text']\",\n",
       " \"['sri_dataset', 'qs3a', 'text']\",\n",
       " \"['sri_dataset', 'qs4', 'double']\",\n",
       " \"['sri_dataset', 'qs5_k_other', 'text']\",\n",
       " \"['sri_dataset', 'qs5_a', 'double']\",\n",
       " \"['sri_dataset', 'qs5_b', 'double']\",\n",
       " \"['sri_dataset', 'qs5_c', 'double']\",\n",
       " \"['sri_dataset', 'qs5_d', 'double']\",\n",
       " \"['sri_dataset', 'qs5_e', 'double']\",\n",
       " \"['sri_dataset', 'qs5_f', 'double']\",\n",
       " \"['sri_dataset', 'qs5_g', 'double']\",\n",
       " \"['sri_dataset', 'qs5_h', 'double']\",\n",
       " \"['sri_dataset', 'qs5_i', 'double']\",\n",
       " \"['sri_dataset', 'qs5_j', 'double']\",\n",
       " \"['sri_dataset', 'qs5_k', 'double']\",\n",
       " \"['sri_dataset', 'qs6_a', 'text']\",\n",
       " \"['sri_dataset', 'qs6_b', 'text']\",\n",
       " \"['sri_dataset', 'qs6_c', 'text']\",\n",
       " \"['sri_dataset', 'qs6_d', 'text']\",\n",
       " \"['sri_dataset', 'qs6_e', 'text']\",\n",
       " \"['sri_dataset', 'confirm', 'text']\",\n",
       " \"['sri_dataset', 'a1_a', 'text']\",\n",
       " \"['sri_dataset', 'a1_b', 'text']\",\n",
       " \"['sri_dataset', 'a1_c', 'text']\",\n",
       " \"['sri_dataset', 'a1_d', 'text']\",\n",
       " \"['sri_dataset', 'a1_e', 'text']\",\n",
       " \"['sri_dataset', 'a1_f', 'text']\",\n",
       " \"['sri_dataset', 'a1_g', 'text']\",\n",
       " \"['sri_dataset', 'a1_h', 'text']\",\n",
       " \"['sri_dataset', 'a1_i', 'text']\",\n",
       " \"['sri_dataset', 'a1_j', 'text']\",\n",
       " \"['sri_dataset', 'a1_k', 'text']\",\n",
       " \"['sri_dataset', 'a1_l', 'text']\",\n",
       " \"['sri_dataset', 'a1_m', 'text']\",\n",
       " \"['sri_dataset', 'a1_n', 'text']\",\n",
       " \"['sri_dataset', 'a1_o', 'text']\",\n",
       " \"['sri_dataset', 'a1_p', 'text']\",\n",
       " \"['sri_dataset', 'a1_q', 'text']\",\n",
       " \"['sri_dataset', 'a1_r', 'text']\",\n",
       " \"['sri_dataset', 'b1_a', 'text']\",\n",
       " \"['sri_dataset', 'b1_b', 'text']\",\n",
       " \"['sri_dataset', 'b1_c', 'text']\",\n",
       " \"['sri_dataset', 'b1_d', 'text']\",\n",
       " \"['sri_dataset', 'b1_e', 'text']\",\n",
       " \"['sri_dataset', 'c1_1_m_other', 'text']\",\n",
       " \"['sri_dataset', 'c1_1_n_other', 'text']\",\n",
       " \"['sri_dataset', 'c1_1_o_other', 'text']\",\n",
       " \"['sri_dataset', 'c1_1_a', 'double']\",\n",
       " \"['sri_dataset', 'c1_1_b', 'double']\",\n",
       " \"['sri_dataset', 'c1_1_c', 'double']\",\n",
       " \"['sri_dataset', 'c1_1_d', 'double']\",\n",
       " \"['sri_dataset', 'c1_1_e', 'double']\",\n",
       " \"['sri_dataset', 'c1_1_f', 'double']\",\n",
       " \"['sri_dataset', 'c1_1_g', 'double']\",\n",
       " \"['sri_dataset', 'c1_1_h', 'double']\",\n",
       " \"['sri_dataset', 'c1_1_i', 'double']\",\n",
       " \"['sri_dataset', 'c1_1_j', 'double']\",\n",
       " \"['sri_dataset', 'c1_1_k', 'double']\",\n",
       " \"['sri_dataset', 'c1_1_l', 'double']\",\n",
       " \"['sri_dataset', 'c1_1_m', 'double']\",\n",
       " \"['sri_dataset', 'c1_1_n', 'double']\",\n",
       " \"['sri_dataset', 'c1_1_o', 'double']\",\n",
       " \"['sri_dataset', 'c1_2_m_other', 'text']\",\n",
       " \"['sri_dataset', 'c1_2_n_other', 'text']\",\n",
       " \"['sri_dataset', 'c1_2_o_other', 'double']\",\n",
       " \"['sri_dataset', 'c1_2_a', 'double']\",\n",
       " \"['sri_dataset', 'c1_2_b', 'double']\",\n",
       " \"['sri_dataset', 'c1_2_c', 'double']\",\n",
       " \"['sri_dataset', 'c1_2_d', 'double']\",\n",
       " \"['sri_dataset', 'c1_2_e', 'double']\",\n",
       " \"['sri_dataset', 'c1_2_f', 'double']\",\n",
       " \"['sri_dataset', 'c1_2_g', 'double']\",\n",
       " \"['sri_dataset', 'c1_2_h', 'double']\",\n",
       " \"['sri_dataset', 'c1_2_i', 'double']\",\n",
       " \"['sri_dataset', 'c1_2_j', 'double']\",\n",
       " \"['sri_dataset', 'c1_2_k', 'double']\",\n",
       " \"['sri_dataset', 'c1_2_l', 'double']\",\n",
       " \"['sri_dataset', 'c1_2_m', 'double']\",\n",
       " \"['sri_dataset', 'c1_2_n', 'double']\",\n",
       " \"['sri_dataset', 'c1_2_o', 'double']\",\n",
       " \"['sri_dataset', 'c1_3_m_other', 'text']\",\n",
       " \"['sri_dataset', 'c1_3_n_other', 'double']\",\n",
       " \"['sri_dataset', 'c1_3_o_other', 'double']\",\n",
       " \"['sri_dataset', 'c1_3_a', 'double']\",\n",
       " \"['sri_dataset', 'c1_3_b', 'double']\",\n",
       " \"['sri_dataset', 'c1_3_c', 'double']\",\n",
       " \"['sri_dataset', 'c1_3_d', 'double']\",\n",
       " \"['sri_dataset', 'c1_3_e', 'double']\",\n",
       " \"['sri_dataset', 'c1_3_f', 'double']\",\n",
       " \"['sri_dataset', 'c1_3_g', 'double']\",\n",
       " \"['sri_dataset', 'c1_3_h', 'double']\",\n",
       " \"['sri_dataset', 'c1_3_i', 'double']\",\n",
       " \"['sri_dataset', 'c1_3_j', 'double']\",\n",
       " \"['sri_dataset', 'c1_3_k', 'double']\",\n",
       " \"['sri_dataset', 'c1_3_l', 'double']\",\n",
       " \"['sri_dataset', 'c1_3_m', 'double']\",\n",
       " \"['sri_dataset', 'c1_3_n', 'double']\",\n",
       " \"['sri_dataset', 'c1_3_o', 'double']\",\n",
       " \"['sri_dataset', 'c2_1_n_other', 'text']\",\n",
       " \"['sri_dataset', 'c2_1_o_other', 'text']\",\n",
       " \"['sri_dataset', 'c2_1_p_other', 'double']\",\n",
       " \"['sri_dataset', 'c2_1_a', 'double']\",\n",
       " \"['sri_dataset', 'c2_1_b', 'double']\",\n",
       " \"['sri_dataset', 'c2_1_c', 'double']\",\n",
       " \"['sri_dataset', 'c2_1_d', 'double']\",\n",
       " \"['sri_dataset', 'c2_1_e', 'double']\",\n",
       " \"['sri_dataset', 'c2_1_f', 'double']\",\n",
       " \"['sri_dataset', 'c2_1_g', 'double']\",\n",
       " \"['sri_dataset', 'c2_1_h', 'double']\",\n",
       " \"['sri_dataset', 'c2_1_i', 'double']\",\n",
       " \"['sri_dataset', 'c2_1_j', 'double']\",\n",
       " \"['sri_dataset', 'c2_1_k', 'double']\",\n",
       " \"['sri_dataset', 'c2_1_l', 'double']\",\n",
       " \"['sri_dataset', 'c2_1_m', 'double']\",\n",
       " \"['sri_dataset', 'c2_1_n', 'double']\",\n",
       " \"['sri_dataset', 'c2_1_o', 'double']\",\n",
       " \"['sri_dataset', 'c2_1_p', 'double']\",\n",
       " \"['sri_dataset', 'c2_2_n_other', 'text']\",\n",
       " \"['sri_dataset', 'c2_2_o_other', 'text']\",\n",
       " \"['sri_dataset', 'c2_2_p_other', 'double']\",\n",
       " \"['sri_dataset', 'c2_2_a', 'double']\",\n",
       " \"['sri_dataset', 'c2_2_b', 'double']\",\n",
       " \"['sri_dataset', 'c2_2_c', 'double']\",\n",
       " \"['sri_dataset', 'c2_2_d', 'double']\",\n",
       " \"['sri_dataset', 'c2_2_e', 'double']\",\n",
       " \"['sri_dataset', 'c2_2_f', 'double']\",\n",
       " \"['sri_dataset', 'c2_2_g', 'double']\",\n",
       " \"['sri_dataset', 'c2_2_h', 'double']\",\n",
       " \"['sri_dataset', 'c2_2_i', 'double']\",\n",
       " \"['sri_dataset', 'c2_2_j', 'double']\",\n",
       " \"['sri_dataset', 'c2_2_k', 'double']\",\n",
       " \"['sri_dataset', 'c2_2_l', 'double']\",\n",
       " \"['sri_dataset', 'c2_2_m', 'double']\",\n",
       " \"['sri_dataset', 'c2_2_n', 'double']\",\n",
       " \"['sri_dataset', 'c2_2_o', 'double']\",\n",
       " \"['sri_dataset', 'c2_2_p', 'double']\",\n",
       " \"['sri_dataset', 'c2_3_n_other', 'text']\",\n",
       " \"['sri_dataset', 'c2_3_o_other', 'text']\",\n",
       " \"['sri_dataset', 'c2_3_p_other', 'text']\",\n",
       " \"['sri_dataset', 'c2_3_a', 'double']\",\n",
       " \"['sri_dataset', 'c2_3_b', 'double']\",\n",
       " \"['sri_dataset', 'c2_3_c', 'double']\",\n",
       " \"['sri_dataset', 'c2_3_d', 'double']\",\n",
       " \"['sri_dataset', 'c2_3_e', 'double']\",\n",
       " \"['sri_dataset', 'c2_3_f', 'double']\",\n",
       " \"['sri_dataset', 'c2_3_g', 'double']\",\n",
       " \"['sri_dataset', 'c2_3_h', 'double']\",\n",
       " \"['sri_dataset', 'c2_3_i', 'double']\",\n",
       " \"['sri_dataset', 'c2_3_j', 'double']\",\n",
       " \"['sri_dataset', 'c2_3_k', 'double']\",\n",
       " \"['sri_dataset', 'c2_3_l', 'double']\",\n",
       " \"['sri_dataset', 'c2_3_m', 'double']\",\n",
       " \"['sri_dataset', 'c2_3_n', 'double']\",\n",
       " \"['sri_dataset', 'c2_3_o', 'double']\",\n",
       " \"['sri_dataset', 'c2_3_p', 'double']\",\n",
       " \"['sri_dataset', 'c3_i_other', 'text']\",\n",
       " \"['sri_dataset', 'c3_j_other', 'double']\",\n",
       " \"['sri_dataset', 'c3_k_other', 'double']\",\n",
       " \"['sri_dataset', 'c3_1_a', 'text']\",\n",
       " \"['sri_dataset', 'c3_1_b', 'text']\",\n",
       " \"['sri_dataset', 'c3_1_c', 'text']\",\n",
       " \"['sri_dataset', 'c3_1_d', 'text']\",\n",
       " \"['sri_dataset', 'c3_1_e', 'text']\",\n",
       " \"['sri_dataset', 'c3_1_f', 'text']\",\n",
       " \"['sri_dataset', 'c3_1_g', 'text']\",\n",
       " \"['sri_dataset', 'c3_1_h', 'text']\",\n",
       " \"['sri_dataset', 'c3_1_i', 'text']\",\n",
       " \"['sri_dataset', 'c3_1_j', 'double']\",\n",
       " \"['sri_dataset', 'c3_1_k', 'double']\",\n",
       " \"['sri_dataset', 'c3_1_l', 'text']\",\n",
       " \"['sri_dataset', 'c3_2_a', 'text']\",\n",
       " \"['sri_dataset', 'c3_2_b', 'text']\",\n",
       " \"['sri_dataset', 'c3_2_c', 'text']\",\n",
       " \"['sri_dataset', 'c3_2_d', 'text']\",\n",
       " \"['sri_dataset', 'c3_2_e', 'text']\",\n",
       " \"['sri_dataset', 'c3_2_f', 'text']\",\n",
       " \"['sri_dataset', 'c3_2_g', 'text']\",\n",
       " \"['sri_dataset', 'c3_2_h', 'text']\",\n",
       " \"['sri_dataset', 'c3_2_i', 'double']\",\n",
       " \"['sri_dataset', 'c3_2_j', 'double']\",\n",
       " \"['sri_dataset', 'c3_2_k', 'double']\",\n",
       " \"['sri_dataset', 'c3_2_l', 'text']\",\n",
       " \"['sri_dataset', 'c3_3_a', 'text']\",\n",
       " \"['sri_dataset', 'c3_3_b', 'text']\",\n",
       " \"['sri_dataset', 'c3_3_c', 'text']\",\n",
       " \"['sri_dataset', 'c3_3_d', 'text']\",\n",
       " \"['sri_dataset', 'c3_3_e', 'text']\",\n",
       " \"['sri_dataset', 'c3_3_f', 'text']\",\n",
       " \"['sri_dataset', 'c3_3_g', 'text']\",\n",
       " \"['sri_dataset', 'c3_3_h', 'text']\",\n",
       " \"['sri_dataset', 'c3_3_i', 'double']\",\n",
       " \"['sri_dataset', 'c3_3_j', 'double']\",\n",
       " \"['sri_dataset', 'c3_3_k', 'double']\",\n",
       " \"['sri_dataset', 'c3_3_l', 'text']\",\n",
       " \"['sri_dataset', 'c4_1_m_other', 'double']\",\n",
       " \"['sri_dataset', 'c4_1_n_other', 'double']\",\n",
       " \"['sri_dataset', 'c4_1_o_other', 'double']\",\n",
       " \"['sri_dataset', 'c4_1_a', 'double']\",\n",
       " \"['sri_dataset', 'c4_1_b', 'double']\",\n",
       " \"['sri_dataset', 'c4_1_c', 'double']\",\n",
       " \"['sri_dataset', 'c4_1_d', 'double']\",\n",
       " \"['sri_dataset', 'c4_1_e', 'double']\",\n",
       " \"['sri_dataset', 'c4_1_f', 'double']\",\n",
       " \"['sri_dataset', 'c4_1_g', 'double']\",\n",
       " \"['sri_dataset', 'c4_1_h', 'double']\",\n",
       " \"['sri_dataset', 'c4_1_i', 'double']\",\n",
       " \"['sri_dataset', 'c4_1_j', 'double']\",\n",
       " \"['sri_dataset', 'c4_1_k', 'double']\",\n",
       " \"['sri_dataset', 'c4_1_l', 'double']\",\n",
       " \"['sri_dataset', 'c4_1_m', 'double']\",\n",
       " \"['sri_dataset', 'c4_1_n', 'double']\",\n",
       " \"['sri_dataset', 'c4_1_o', 'double']\",\n",
       " \"['sri_dataset', 'c4_2_m_other', 'text']\",\n",
       " \"['sri_dataset', 'c4_2_n_other', 'text']\",\n",
       " \"['sri_dataset', 'c4_2_o_other', 'double']\",\n",
       " \"['sri_dataset', 'c4_2_a', 'double']\",\n",
       " \"['sri_dataset', 'c4_2_b', 'double']\",\n",
       " \"['sri_dataset', 'c4_2_c', 'double']\",\n",
       " \"['sri_dataset', 'c4_2_d', 'double']\",\n",
       " \"['sri_dataset', 'c4_2_e', 'double']\",\n",
       " \"['sri_dataset', 'c4_2_f', 'double']\",\n",
       " \"['sri_dataset', 'c4_2_g', 'double']\",\n",
       " \"['sri_dataset', 'c4_2_h', 'double']\",\n",
       " \"['sri_dataset', 'c4_2_i', 'double']\",\n",
       " \"['sri_dataset', 'c4_2_j', 'double']\",\n",
       " \"['sri_dataset', 'c4_2_k', 'double']\",\n",
       " \"['sri_dataset', 'c4_2_l', 'double']\",\n",
       " \"['sri_dataset', 'c4_2_m', 'double']\",\n",
       " \"['sri_dataset', 'c4_2_n', 'double']\",\n",
       " \"['sri_dataset', 'c4_2_o', 'double']\",\n",
       " \"['sri_dataset', 'c4_3_m_other', 'text']\",\n",
       " \"['sri_dataset', 'c4_3_n_other', 'double']\",\n",
       " \"['sri_dataset', 'c4_3_o_other', 'double']\",\n",
       " \"['sri_dataset', 'c4_3_a', 'double']\",\n",
       " \"['sri_dataset', 'c4_3_b', 'double']\",\n",
       " \"['sri_dataset', 'c4_3_c', 'double']\",\n",
       " \"['sri_dataset', 'c4_3_d', 'double']\",\n",
       " \"['sri_dataset', 'c4_3_e', 'double']\",\n",
       " \"['sri_dataset', 'c4_3_f', 'double']\",\n",
       " \"['sri_dataset', 'c4_3_g', 'double']\",\n",
       " \"['sri_dataset', 'c4_3_h', 'double']\",\n",
       " \"['sri_dataset', 'c4_3_i', 'double']\",\n",
       " \"['sri_dataset', 'c4_3_j', 'double']\",\n",
       " \"['sri_dataset', 'c4_3_k', 'double']\",\n",
       " \"['sri_dataset', 'c4_3_l', 'double']\",\n",
       " \"['sri_dataset', 'c4_3_m', 'double']\",\n",
       " \"['sri_dataset', 'c4_3_n', 'double']\",\n",
       " \"['sri_dataset', 'c4_3_o', 'double']\",\n",
       " \"['sri_dataset', 'c5_1_n_other', 'text']\",\n",
       " \"['sri_dataset', 'c5_1_o_other', 'text']\",\n",
       " \"['sri_dataset', 'c5_1_p_other', 'text']\",\n",
       " \"['sri_dataset', 'c5_1_a', 'double']\",\n",
       " \"['sri_dataset', 'c5_1_b', 'double']\",\n",
       " \"['sri_dataset', 'c5_1_c', 'double']\",\n",
       " \"['sri_dataset', 'c5_1_d', 'double']\",\n",
       " \"['sri_dataset', 'c5_1_e', 'double']\",\n",
       " \"['sri_dataset', 'c5_1_f', 'double']\",\n",
       " \"['sri_dataset', 'c5_1_g', 'double']\",\n",
       " \"['sri_dataset', 'c5_1_h', 'double']\",\n",
       " \"['sri_dataset', 'c5_1_i', 'double']\",\n",
       " \"['sri_dataset', 'c5_1_j', 'double']\",\n",
       " \"['sri_dataset', 'c5_1_k', 'double']\",\n",
       " \"['sri_dataset', 'c5_1_l', 'double']\",\n",
       " \"['sri_dataset', 'c5_1_m', 'double']\",\n",
       " \"['sri_dataset', 'c5_1_n', 'double']\",\n",
       " \"['sri_dataset', 'c5_1_o', 'double']\",\n",
       " \"['sri_dataset', 'c5_1_p', 'double']\",\n",
       " \"['sri_dataset', 'c5_2_n_other', 'double']\",\n",
       " \"['sri_dataset', 'c5_2_o_other', 'double']\",\n",
       " \"['sri_dataset', 'c5_2_p_other', 'double']\",\n",
       " \"['sri_dataset', 'c5_2_a', 'double']\",\n",
       " \"['sri_dataset', 'c5_2_b', 'double']\",\n",
       " \"['sri_dataset', 'c5_2_c', 'double']\",\n",
       " \"['sri_dataset', 'c5_2_d', 'double']\",\n",
       " \"['sri_dataset', 'c5_2_e', 'double']\",\n",
       " \"['sri_dataset', 'c5_2_f', 'double']\",\n",
       " \"['sri_dataset', 'c5_2_g', 'double']\",\n",
       " \"['sri_dataset', 'c5_2_h', 'double']\",\n",
       " \"['sri_dataset', 'c5_2_i', 'double']\",\n",
       " \"['sri_dataset', 'c5_2_j', 'double']\",\n",
       " \"['sri_dataset', 'c5_2_k', 'double']\",\n",
       " \"['sri_dataset', 'c5_2_l', 'double']\",\n",
       " \"['sri_dataset', 'c5_2_m', 'double']\",\n",
       " \"['sri_dataset', 'c5_2_n', 'double']\",\n",
       " \"['sri_dataset', 'c5_2_o', 'double']\",\n",
       " \"['sri_dataset', 'c5_2_p', 'double']\",\n",
       " \"['sri_dataset', 'c5_3_n_other', 'text']\",\n",
       " \"['sri_dataset', 'c5_3_o_other', 'text']\",\n",
       " \"['sri_dataset', 'c5_3_p_other', 'text']\",\n",
       " \"['sri_dataset', 'c5_3_a', 'double']\",\n",
       " \"['sri_dataset', 'c5_3_b', 'double']\",\n",
       " \"['sri_dataset', 'c5_3_c', 'double']\",\n",
       " \"['sri_dataset', 'c5_3_d', 'double']\",\n",
       " \"['sri_dataset', 'c5_3_e', 'double']\",\n",
       " \"['sri_dataset', 'c5_3_f', 'double']\",\n",
       " \"['sri_dataset', 'c5_3_g', 'double']\",\n",
       " \"['sri_dataset', 'c5_3_h', 'double']\",\n",
       " \"['sri_dataset', 'c5_3_i', 'double']\",\n",
       " \"['sri_dataset', 'c5_3_j', 'double']\",\n",
       " \"['sri_dataset', 'c5_3_k', 'double']\",\n",
       " \"['sri_dataset', 'c5_3_l', 'double']\",\n",
       " \"['sri_dataset', 'c5_3_m', 'double']\",\n",
       " \"['sri_dataset', 'c5_3_n', 'double']\",\n",
       " \"['sri_dataset', 'c5_3_o', 'double']\",\n",
       " \"['sri_dataset', 'c5_3_p', 'double']\",\n",
       " \"['sri_dataset', 'c6_1_n_other', 'text']\",\n",
       " \"['sri_dataset', 'c6_1_o_other', 'double']\",\n",
       " \"['sri_dataset', 'c6_1_p_other', 'double']\",\n",
       " \"['sri_dataset', 'c6_1_a', 'double']\",\n",
       " \"['sri_dataset', 'c6_1_b', 'double']\",\n",
       " \"['sri_dataset', 'c6_1_c', 'double']\",\n",
       " \"['sri_dataset', 'c6_1_d', 'double']\",\n",
       " \"['sri_dataset', 'c6_1_e', 'double']\",\n",
       " \"['sri_dataset', 'c6_1_f', 'double']\",\n",
       " \"['sri_dataset', 'c6_1_g', 'double']\",\n",
       " \"['sri_dataset', 'c6_1_h', 'double']\",\n",
       " \"['sri_dataset', 'c6_1_i', 'double']\",\n",
       " \"['sri_dataset', 'c6_1_j', 'double']\",\n",
       " \"['sri_dataset', 'c6_1_k', 'double']\",\n",
       " \"['sri_dataset', 'c6_1_l', 'double']\",\n",
       " \"['sri_dataset', 'c6_1_m', 'double']\",\n",
       " \"['sri_dataset', 'c6_1_n', 'double']\",\n",
       " \"['sri_dataset', 'c6_1_o', 'double']\",\n",
       " \"['sri_dataset', 'c6_1_p', 'double']\",\n",
       " \"['sri_dataset', 'c6_2_n_other', 'double']\",\n",
       " \"['sri_dataset', 'c6_2_o_other', 'double']\",\n",
       " \"['sri_dataset', 'c6_2_p_other', 'double']\",\n",
       " \"['sri_dataset', 'c6_2_a', 'double']\",\n",
       " \"['sri_dataset', 'c6_2_b', 'double']\",\n",
       " \"['sri_dataset', 'c6_2_c', 'double']\",\n",
       " \"['sri_dataset', 'c6_2_d', 'double']\",\n",
       " \"['sri_dataset', 'c6_2_e', 'double']\",\n",
       " \"['sri_dataset', 'c6_2_f', 'double']\",\n",
       " \"['sri_dataset', 'c6_2_g', 'double']\",\n",
       " \"['sri_dataset', 'c6_2_h', 'double']\",\n",
       " \"['sri_dataset', 'c6_2_i', 'double']\",\n",
       " \"['sri_dataset', 'c6_2_j', 'double']\",\n",
       " \"['sri_dataset', 'c6_2_k', 'double']\",\n",
       " \"['sri_dataset', 'c6_2_l', 'double']\",\n",
       " \"['sri_dataset', 'c6_2_m', 'double']\",\n",
       " \"['sri_dataset', 'c6_2_n', 'double']\",\n",
       " \"['sri_dataset', 'c6_2_o', 'double']\",\n",
       " \"['sri_dataset', 'c6_2_p', 'double']\",\n",
       " \"['sri_dataset', 'c6_3_n_other', 'text']\",\n",
       " \"['sri_dataset', 'c6_3_o_other', 'text']\",\n",
       " \"['sri_dataset', 'c6_3_p_other', 'double']\",\n",
       " \"['sri_dataset', 'c6_3_a', 'double']\",\n",
       " \"['sri_dataset', 'c6_3_b', 'double']\",\n",
       " \"['sri_dataset', 'c6_3_c', 'double']\",\n",
       " \"['sri_dataset', 'c6_3_d', 'double']\",\n",
       " \"['sri_dataset', 'c6_3_e', 'double']\",\n",
       " \"['sri_dataset', 'c6_3_f', 'double']\",\n",
       " \"['sri_dataset', 'c6_3_g', 'double']\",\n",
       " \"['sri_dataset', 'c6_3_h', 'double']\",\n",
       " \"['sri_dataset', 'c6_3_i', 'double']\",\n",
       " \"['sri_dataset', 'c6_3_j', 'double']\",\n",
       " \"['sri_dataset', 'c6_3_k', 'double']\",\n",
       " \"['sri_dataset', 'c6_3_l', 'double']\",\n",
       " \"['sri_dataset', 'c6_3_m', 'double']\",\n",
       " \"['sri_dataset', 'c6_3_n', 'double']\",\n",
       " \"['sri_dataset', 'c6_3_o', 'double']\",\n",
       " \"['sri_dataset', 'c6_3_p', 'double']\",\n",
       " \"['sri_dataset', 'd1_a', 'double']\",\n",
       " \"['sri_dataset', 'd1_b', 'double']\",\n",
       " \"['sri_dataset', 'd1_c', 'double']\",\n",
       " \"['sri_dataset', 'd2_a', 'double']\",\n",
       " \"['sri_dataset', 'd2_b', 'double']\",\n",
       " \"['sri_dataset', 'd2_c', 'double']\",\n",
       " \"['sri_dataset', 'd3_a', 'double']\",\n",
       " \"['sri_dataset', 'd3_b', 'double']\",\n",
       " \"['sri_dataset', 'd3_c', 'double']\",\n",
       " \"['sri_dataset', 'd4_1_e_other', 'text']\",\n",
       " \"['sri_dataset', 'd4_2_f_other', 'double']\",\n",
       " \"['sri_dataset', 'd4_3_g_other', 'text']\",\n",
       " \"['sri_dataset', 'd4_1_a', 'text']\",\n",
       " \"['sri_dataset', 'd4_1_b', 'text']\",\n",
       " \"['sri_dataset', 'd4_1_c', 'text']\",\n",
       " \"['sri_dataset', 'd4_1_d', 'text']\",\n",
       " \"['sri_dataset', 'd4_1_e', 'text']\",\n",
       " \"['sri_dataset', 'd4_2_a', 'text']\",\n",
       " \"['sri_dataset', 'd4_2_b', 'text']\",\n",
       " \"['sri_dataset', 'd4_2_c', 'text']\",\n",
       " \"['sri_dataset', 'd4_2_d', 'text']\",\n",
       " \"['sri_dataset', 'd4_2_f', 'double']\",\n",
       " \"['sri_dataset', 'd4_3_a', 'text']\",\n",
       " \"['sri_dataset', 'd4_3_b', 'text']\",\n",
       " \"['sri_dataset', 'd4_3_c', 'text']\",\n",
       " \"['sri_dataset', 'd4_3_d', 'text']\",\n",
       " \"['sri_dataset', 'd4_3_g', 'text']\",\n",
       " \"['sri_dataset', 'd5_g_other', 'double']\",\n",
       " \"['sri_dataset', 'd5_a', 'double']\",\n",
       " \"['sri_dataset', 'd5_b', 'double']\",\n",
       " \"['sri_dataset', 'd5_c', 'double']\",\n",
       " \"['sri_dataset', 'd5_d', 'double']\",\n",
       " \"['sri_dataset', 'd5_e', 'double']\",\n",
       " \"['sri_dataset', 'd5_f', 'double']\",\n",
       " \"['sri_dataset', 'd5_g', 'double']\",\n",
       " \"['sri_dataset', 'd6', 'text']\",\n",
       " \"['sri_dataset', 'd7', 'text']\",\n",
       " \"['unemployment_level', 'DATE', 'datetime']\",\n",
       " \"['unemployment_level', 'UNEMPLOY', 'bigint']\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38df0586-5005-4610-9045-bdc9bd6467fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnretriever_db = FAISS.from_texts(metadata,embedding=OpenAIEmbeddings(model=\"text-embedding-3-large\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef02a31c-72d8-4628-aec2-2bf464fd6cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def retriever(query, k=5):\n",
    "#     results = columnretriever_db.similarity_search(query, k=k)\n",
    "#     contexts = [result.page_content for result in results]\n",
    "#     return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "533bd490-53b4-46a6-b74f-22925300445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_response(query: str):\n",
    "#     # Retrieve context\n",
    "#     contexts = retriever(query, k=5)\n",
    "\n",
    "#     chat = ChatOpenAI(model=\"gpt-4o-mini\",\n",
    "#                       temperature=0,\n",
    "#                       model_kwargs={\"seed\": 42})\n",
    "\n",
    "#     messages = [\n",
    "#         SystemMessage(\n",
    "#             content=f\"You are a business analyst designed to give key insights. You have access to the following context: {contexts}. You are task is to provide the specific columns that related to query.Provide your response in JSON format. For example: {{\\n\"\n",
    "#                     '\"TABLENAMEA\": [[\"COLUMNNAMEA\", \"DATATYPEA\"], [\"COLUMNNAMEB\", \"DATATYPEB\"]],\\n'\n",
    "#                     '\"TABLENAMEB\": [[\"COLUMNNAMEA\", \"DATATYPEA\"], [\"COLUMNNAMEB\", \"DATATYPEB\"]]\\n'\n",
    "#                     '}}'),\n",
    "#         HumanMessage(\n",
    "#             content=query),\n",
    "#     ]\n",
    "\n",
    "#     return json.loads(chat(messages).content)\n",
    "#     # response = chat(messages.content)\n",
    "#     # return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b6e286e-881b-4a93-8a22-dce9c2bc263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resultant_df(query, db_metadata, connection):\n",
    "    results = columnretriever_db.similarity_search(query, k=10)\n",
    "    contexts = [result.page_content for result in results]\n",
    "    print(contexts)\n",
    "\n",
    "    chart_hints = faiss_hints.similarity_search(query, k=1)\n",
    "    knowledge_glossary = knowledge_hints.similarity_search(query, k=3)\n",
    "\n",
    "    chart_class = get_llm_response(\n",
    "        prompt_file_path=\"prompts/chart_class2.txt\",\n",
    "        llm=llm,\n",
    "        input_variables={\n",
    "            \"db_metadata\": db_metadata,\"question\": query,\"chart_hints\": chart_hints[0].page_content,\"contexts\": contexts},\n",
    "        pydantic_class=ChartClass\n",
    "    )\n",
    "\n",
    "    print(chart_class)\n",
    "\n",
    "    if chart_class.is_chart_possible == \"Yes\":\n",
    "        derived = None\n",
    "        tables_columns = chart_class.tables_columns\n",
    "        table_name = list(tables_columns.keys())[0]\n",
    "        print(table_name)\n",
    "        columns = list(tables_columns.values())\n",
    "        print(columns)\n",
    "        if chart_class.is_derived:\n",
    "            derived_response = get_llm_response(\n",
    "                prompt_file_path=\"prompts/math_preprocessing.txt\",\n",
    "                llm=llm,\n",
    "                input_variables={\"db_metadata\": tables_columns,\"knowledge_glossary\": knowledge_glossary,\"query\": query})\n",
    "            derived = derived_response.content\n",
    "            print(f\"derived: {derived}\")\n",
    "\n",
    "        chart_config = get_llm_response(\n",
    "            prompt_file_path=\"prompts/chart_config.txt\",\n",
    "            llm=llm,\n",
    "            input_variables={\"chart_class\": chart_class,\"question\": query,\"db_metadata\": tables_columns},\n",
    "            pydantic_class=ChartConfig\n",
    "        )\n",
    "        print()\n",
    "        print(chart_config)\n",
    "      \n",
    "        if derived:\n",
    "            derived = json.loads(derived)\n",
    "            mysql_pandas_df = MySQLPandasDF(\n",
    "                chart_config=chart_config.model_dump(),\n",
    "                connection=connection,\n",
    "                table=table_name,\n",
    "                derived=derived\n",
    "            )\n",
    "        else:\n",
    "            mysql_pandas_df = MySQLPandasDF(\n",
    "                chart_config=chart_config.model_dump(),\n",
    "                connection=connection,\n",
    "                table=table_name\n",
    "            )\n",
    "\n",
    "        metric_type = chart_class.type\n",
    "        resultant_df = mysql_pandas_df.generate_resultant_df(metric_type)\n",
    "        return resultant_df\n",
    "\n",
    "    elif chart_class.is_chart_possible == \"No\":\n",
    "        reject_reason = get_llm_response(\n",
    "            prompt_file_path='prompts/RejectClass.txt',\n",
    "            pydantic_class=RejectClass,\n",
    "            input_variables={\n",
    "                \"db_metadata\": db_metadata,\n",
    "                \"question\": query\n",
    "            },\n",
    "            llm=llm\n",
    "        )\n",
    "        print(\"Reject Reason\\n\")\n",
    "        print(reject_reason.suggested_alternatives)\n",
    "\n",
    "        new_query = reject_reason.suggested_alternatives[0] if reject_reason.suggested_alternatives else reject_reason.suggested_alternatives\n",
    "        return get_resultant_df(query=new_query, db_metadata=db_metadata, connection=connection)\n",
    "\n",
    "    else:\n",
    "        rephrase_query = get_llm_response(\n",
    "            prompt_file_path=\"prompts/rephrase.txt\",\n",
    "            pydantic_class=RephraseClass,\n",
    "            input_variables={\n",
    "                \"db_metadata\": db_metadata,\n",
    "                \"question\": query\n",
    "            },\n",
    "            llm=llm\n",
    "        )\n",
    "\n",
    "        new_query = rephrase_query.rephrased_query\n",
    "        print(new_query)\n",
    "        return get_resultant_df(query=new_query, db_metadata=db_metadata, connection=connection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "773807a4-a585-4a5f-8601-421c09bb01a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_resultant_df(query, table,db_metadata, connection):\n",
    "#     results = columnretriever_db.similarity_search(query, k=3)\n",
    "#     contexts = [result.page_content for result in results]\n",
    "#     print(contexts)\n",
    "\n",
    "#     chart_hints = faiss_hints.similarity_search(query, k=1)\n",
    "#     knowledge_glossary = knowledge_hints.similarity_search(query, k=3)\n",
    "\n",
    "#     chart_class = get_llm_response(\n",
    "#         prompt_file_path=\"prompts/chart_class2.txt\",\n",
    "#         llm=llm,\n",
    "#         input_variables={\n",
    "#             \"db_metadata\": db_metadata,\"question\": query,\"chart_hints\": chart_hints[0].page_content,\"contexts\": contexts},\n",
    "#         pydantic_class=ChartClass\n",
    "#     )\n",
    "\n",
    "#     print(chart_class)\n",
    "\n",
    "#     if chart_class.is_chart_possible == \"Yes\":\n",
    "#         derived = None\n",
    "#         if chart_class.is_derived:\n",
    "#             derived_response = get_llm_response(\n",
    "#                 prompt_file_path=\"prompts/math_preprocessing.txt\",\n",
    "#                 llm=llm,\n",
    "#                 input_variables={\"db_metadata\": db_metadata,\"knowledge_glossary\": knowledge_glossary,\"query\": query})\n",
    "#             derived = derived_response.content\n",
    "#             print(f\"derived: {derived}\")\n",
    "\n",
    "#         chart_config = get_llm_response(\n",
    "#             prompt_file_path=\"prompts/chart_config.txt\",\n",
    "#             llm=llm,\n",
    "#             input_variables={\"chart_class\": chart_class,\"question\": query,\"db_metadata\": db_metadata},\n",
    "#             pydantic_class=ChartConfig\n",
    "#         )\n",
    "#         print()\n",
    "#         print(chart_config)\n",
    "\n",
    "#         if derived:\n",
    "#             derived = json.loads(derived)\n",
    "#             mysql_pandas_df = MySQLPandasDF(\n",
    "#                 chart_config=chart_config.model_dump(),\n",
    "#                 connection=connection,\n",
    "#                 table=table,\n",
    "#                 derived=derived\n",
    "#             )\n",
    "#         else:\n",
    "#             mysql_pandas_df = MySQLPandasDF(\n",
    "#                 chart_config=chart_config.model_dump(),\n",
    "#                 connection=connection,\n",
    "#                 table=table\n",
    "#             )\n",
    "\n",
    "#         metric_type = chart_class.type\n",
    "#         resultant_df = mysql_pandas_df.generate_resultant_df(metric_type)\n",
    "#         return resultant_df\n",
    "\n",
    "#     elif chart_class.is_chart_possible == \"No\":\n",
    "#         reject_reason = get_llm_response(\n",
    "#             prompt_file_path='prompts/RejectClass.txt',\n",
    "#             pydantic_class=RejectClass,\n",
    "#             input_variables={\n",
    "#                 \"db_metadata\": db_metadata,\n",
    "#                 \"question\": query\n",
    "#             },\n",
    "#             llm=llm\n",
    "#         )\n",
    "#         print(\"Reject Reason\\n\")\n",
    "#         print(reject_reason.suggested_alternatives)\n",
    "\n",
    "#         new_query = reject_reason.suggested_alternatives[0] if reject_reason.suggested_alternatives else reject_reason.suggested_alternatives\n",
    "#         return get_resultant_df(query=new_query, table=table, db_metadata=db_metadata, connection=connection)\n",
    "\n",
    "#     else:\n",
    "#         rephrase_query = get_llm_response(\n",
    "#             prompt_file_path=\"prompts/rephrase.txt\",\n",
    "#             pydantic_class=RephraseClass,\n",
    "#             input_variables={\n",
    "#                 \"db_metadata\": db_metadata,\n",
    "#                 \"question\": query\n",
    "#             },\n",
    "#             llm=llm\n",
    "#         )\n",
    "\n",
    "#         new_query = rephrase_query.rephrased_query\n",
    "#         print(new_query)\n",
    "#         return get_resultant_df(query=new_query, table=table,db_metadata=db_metadata, connection=connection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262a7c7d-c4f5-4dbe-9112-849eceb9785f",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd2a6f17-29f6-4fe7-aa5d-ea7aed0f03fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TABLE_NAME</th>\n",
       "      <th>COLUMN_NAME</th>\n",
       "      <th>DATA_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auto_insurance</td>\n",
       "      <td>Customer</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auto_insurance</td>\n",
       "      <td>State</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>auto_insurance</td>\n",
       "      <td>Customer Lifetime Value</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>auto_insurance</td>\n",
       "      <td>Response</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>auto_insurance</td>\n",
       "      <td>Coverage</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>sri_dataset</td>\n",
       "      <td>d5_g</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>sri_dataset</td>\n",
       "      <td>d6</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>sri_dataset</td>\n",
       "      <td>d7</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>unemployment_level</td>\n",
       "      <td>DATE</td>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>unemployment_level</td>\n",
       "      <td>UNEMPLOY</td>\n",
       "      <td>bigint</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>719 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             TABLE_NAME              COLUMN_NAME DATA_TYPE\n",
       "0        auto_insurance                 Customer      text\n",
       "1        auto_insurance                    State      text\n",
       "2        auto_insurance  Customer Lifetime Value    double\n",
       "3        auto_insurance                 Response      text\n",
       "4        auto_insurance                 Coverage      text\n",
       "..                  ...                      ...       ...\n",
       "714         sri_dataset                     d5_g    double\n",
       "715         sri_dataset                       d6      text\n",
       "716         sri_dataset                       d7      text\n",
       "717  unemployment_level                     DATE  datetime\n",
       "718  unemployment_level                 UNEMPLOY    bigint\n",
       "\n",
       "[719 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_metadata = get_all_tables_metadata(engine)\n",
    "# db_metadata = db_metadata.to_csv()\n",
    "db_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c32473-ec90-415a-86f6-c9f789007287",
   "metadata": {},
   "source": [
    "### distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa467e2b-6ae4-4155-a47d-e2aafdfe4d9f",
   "metadata": {},
   "source": [
    "For the given Metadata of the datasets\n",
    "\n",
    "[\"['sales_data', 'date', 'datetime']\",\"['sales_data', 'day of the week', 'text']\",\"['sales_data', 'product_id', 'bigint']\",\"['sales_data', 'sales_amount', 'double']\",\"['sales_data', 'gender', 'text']\",\"['product_categories', 'product_id', 'bigint']\",\"['product_categories', 'category', 'text']\",\n",
    "\"['product_categories', 'cost', 'double']\",\"['product_categories', 'quantity', 'bigint']\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacd2188-f703-456e-b0fe-8121ef8a9e2a",
   "metadata": {},
   "source": [
    "{question: , table , columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "df2b97f6-3a2f-4649-9792-8012212ced91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"['auto_insurance', 'Marital Status', 'text']\", \"['bank_demog', 'marital', 'text']\", \"['auto_insurance', 'Income', 'bigint']\", \"['auto_insurance', 'EmploymentStatus', 'text']\", \"['ecom_sales', 'Profit', 'double']\", \"['ecom_sales', 'Sales', 'double']\", \"['cgr_premiums', 'gender', 'text']\", \"['generic_percentage_data', 'No Coverage / Out-of-pocket (%)', 'double']\", \"['ecommerce', 'Profit', 'double']\", \"['auto_insurance', 'Customer Lifetime Value', 'double']\"]\n",
      "thought=\"The query asks for a relationship between 'Income' and 'Marital Status'. Both 'Income' and 'Marital Status' are present in the 'auto_insurance' dataset. This suggests that we can analyze the correlation or distribution between these columns.\" is_chart_possible='Yes' tables_columns={'auto_insurance': ['Income', 'Marital Status']} chart_type='scatter plot' type='relational' is_derived=False\n",
      "auto_insurance\n",
      "[['Income', 'Marital Status']]\n",
      "\n",
      "x_axis='Marital Status' y_axis='Income' binning=None heading='Income by Marital Status' group_by=None operation=None chart_type='scatter plot'\n",
      "metric_type:  relational\n",
      "CPU times: total: 328 ms\n",
      "Wall time: 7.52 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Married</td>\n",
       "      <td>56274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Single</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Married</td>\n",
       "      <td>48767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Married</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Single</td>\n",
       "      <td>43836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9129</th>\n",
       "      <td>Married</td>\n",
       "      <td>71941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9130</th>\n",
       "      <td>Divorced</td>\n",
       "      <td>21604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9131</th>\n",
       "      <td>Single</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9132</th>\n",
       "      <td>Married</td>\n",
       "      <td>21941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9133</th>\n",
       "      <td>Single</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9134 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Marital Status  Income\n",
       "0           Married   56274\n",
       "1            Single       0\n",
       "2           Married   48767\n",
       "3           Married       0\n",
       "4            Single   43836\n",
       "...             ...     ...\n",
       "9129        Married   71941\n",
       "9130       Divorced   21604\n",
       "9131         Single       0\n",
       "9132        Married   21941\n",
       "9133         Single       0\n",
       "\n",
       "[9134 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from loguru import logger\n",
    "connection = engine.connect()\n",
    "query = \"Income by Marital Status\"\n",
    "df =get_resultant_df(query = query,db_metadata=db_metadata,connection = connection)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "078e853c-c278-487e-a911-a2eb0b8433b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rephrase\n",
    "# Ratio of premium ticket types to other ticket types by gender\n",
    "# Yes\n",
    "# derived:{\"thought\":\"To calculate the ratio of premium ticket types to other ticket types by gender, we need to count the number of premium ticket types and the number of other ticket types for each gender. Then, we can divide the number of premium ticket types by the number of other ticket types for each gender.\",\"formula\":\"COUNT(Ticket_Type='Premium')/COUNT(Ticket_Type!='Premium') BY Customer_Gender\",\"term\":\"premium_to_other_ticket_ratio_by_gender\"}\n",
    "# metric_type:  group_aggregates\n",
    "# SELECT `Customer Gender`,\n",
    " #                   none(`Ticket Type`) AS `Ticket Type`\n",
    " #            FROM `customer_support` GROUP BY `Customer Gender`]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1e7409-d3a3-409d-9fb5-4f332f988332",
   "metadata": {},
   "source": [
    "### Relational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbf253a-a64a-4fe6-ac20-eb081c9d1e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = engine.connect()\n",
    "table = \"ecommerce\"\n",
    "query = \"relation between profit and quantity\"\n",
    "df =get_resultant_df(query = query,table = \"ecommerce\",db_metadata = db_metadata,connection = connection)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08b60cd-490a-4326-b25e-fb431718edaa",
   "metadata": {},
   "source": [
    "### Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e3f142-005d-49a0-9394-42420ed76622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "connection = engine.connect()\n",
    "table = \"ecommerce\"\n",
    "query = \"profits over time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c20b6f3-797f-4728-a8ae-d874624a518e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df =get_resultant_df(query = query,table = \"ecommerce\",db_metadata = db_metadata,connection = connection)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb6d156-c070-47c9-aea0-33e235bdea99",
   "metadata": {},
   "source": [
    "### Derived Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f90be63-0267-421f-b49a-6c2ab0a2f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = engine.connect()\n",
    "table = \"ecommerce\"\n",
    "query = \"Average order value over time\"\n",
    "df =get_resultant_df(query = query,table = \"ecommerce\",db_metadata = db_metadata,connection = connection)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e398108e-0d5a-4693-85c4-aad438575fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_glossary = [average_order_value,gross_profit_margin,return_on_investment,customer_acquistion_cost,customer_lifetime_value,sales_growth,customer_satisfaction_score]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedc29f1-38d3-4b01-a96c-2a56c121e189",
   "metadata": {},
   "source": [
    "## Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17941cd7-14eb-4049-ac2c-ed88709977c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6e3db0e-deba-4938-ba36-42d44768b606",
   "metadata": {},
   "source": [
    "## Rough Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fec090e-e4ba-49b1-b8ff-5d29e58c9c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chart_class = get_llm_response(prompt_file_path=\"prompts/chart_class.txt\",llm=llm,input_variables={\"db_metadata\":db_metadata,\"question\":\"weather trend over time\"},pydantic_class=ChartClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748748a3-63ac-41ee-b6cf-9e2314b55ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chart_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b2080-a850-4a08-8eae-6ff085daac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reject_reason = get_llm_response(prompt_file_path='prompts/RejectClass.txt',pydantic_class=RejectClass,input_variables={\"db_metadata\":db_metadata,\"question\":\"weather trend over time\"},llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cfc7c6-74b3-4906-897d-c5a86374351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reject_reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a759c3-6d0c-4344-8bc0-3cac4ea263e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_variables = {\"db_metadata\":db_metadata,\"question\":\"sales\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7dd6ae-1d07-489f-8a08-a2b4e2ecd24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rephrase_query = get_llm_response(prompt_file_path=\"prompts/rephrase.txt\",pydantic_class=RephraseClass,input_variables={\"db_metadata\":db_metadata,\"question\":\"sales\"},llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a7ef74-3307-4118-b31c-f7415a804d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rephrase_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597d4615-44fd-4f53-9f27-4308cde3737e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
