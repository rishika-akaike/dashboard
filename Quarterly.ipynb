{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ad59615-da92-4a53-8f38-f99f7c0544c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\HP\\\\OneDrive\\\\Desktop\\\\Akaike\\\\Basics'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Users\\\\HP\\\\OneDrive\\\\Desktop\\\\Akaike\\\\Basics')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e2c93-2667-4ddb-b1e2-b786d38926a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "from sqlalchemy import create_engine,MetaData,text\n",
    "import plotly.graph_objects as go\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed25e7ea-ea37-46c2-ae1a-94baac4f4e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain_community.chat_models import  ChatOpenAI\n",
    "from loguru import logger\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edd08c3-ffb7-4e6d-9177-547f1ccd3b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def identify_columns(df):\n",
    "    categorical_cols = {}\n",
    "    date_cols = {}\n",
    "    numerical_cols = {}\n",
    "\n",
    "    # Define a regular expression for typical date patterns\n",
    "    date_pattern = re.compile(r'\\b\\d{1,2}[-/](Jan.*|Feb.*|Mar.*|Apr.*|May|Jun.*|Jul.*|Aug.*|Sep.*|Oct.*|Nov.*|Dec.*)[a-z]*[-/]\\d{2,4}\\b', re.IGNORECASE)\n",
    "    currency_pattern = re.compile(r'^[$€£₹]\\s?(?:\\d{1,3}(?:[,]\\d{3})*(?:[,]\\d{3})*(?:[.]\\d{2})?|\\d+(?:[.]\\d{2})?)$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "    for col in df.columns:\n",
    "        # For object types, check if the column values match the date pattern or currency pattern\n",
    "        if df[col].dtype == 'object':\n",
    "            # If any value matches the date pattern, attempt conversion\n",
    "            if any(date_pattern.match(str(x)) for x in df[col]):\n",
    "                temp_col = pd.to_datetime(df[col], errors='coerce')\n",
    "                if not temp_col.isnull().all():  # If conversion is successful\n",
    "                    df[col] = temp_col\n",
    "                    date_cols[col] = {\"range\":(df[col].min(),df[col].max())}\n",
    "                    continue\n",
    "\n",
    "            # If any value matches the currency pattern, consider it numerical\n",
    "            elif any(currency_pattern.match(str(x)) for x in df[col]):\n",
    "                try:\n",
    "                    temp_col = pd.to_numeric(df[col].str.replace(r'[$€£₹,]', ''), errors='coerce')\n",
    "                    if not temp_col.isnull().all():\n",
    "                        df[col] = temp_col\n",
    "                        numerical_cols[col] = {\"range\":(df[col].min(), df[col].max())}\n",
    "                        continue\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        # For int types, attempt conversion only if values are in a typical timestamp range\n",
    "        elif df[col].dtype == 'int64':\n",
    "            if df[col].between(1e9, 1e12).any():  # Rough range for UNIX timestamps\n",
    "                temp_col = pd.to_datetime(df[col], unit='s', errors='coerce')\n",
    "                if not temp_col.isnull().all():\n",
    "                    df[col] = temp_col\n",
    "                    date_cols[col] = {\"range\":(df[col].min(), df[col].max())}\n",
    "                    continue\n",
    "\n",
    "        # Identify categorical columns\n",
    "        if df[col].dtype == 'object' or df[col].dtype.name == 'category':\n",
    "            try:\n",
    "                temp_dates = pd.to_datetime(df[col], errors='coerce')\n",
    "                valid_dates = temp_dates.dropna()\n",
    "                if not valid_dates.empty:\n",
    "                    min_date = valid_dates.min()\n",
    "                    max_date = valid_dates.max()\n",
    "                    date_cols[col] = (min_date, max_date)\n",
    "            except:\n",
    "                pass\n",
    "            if df[col].nunique() < 10:\n",
    "                categorical_cols[col] = df[col].unique().tolist()\n",
    "\n",
    "        # Identify date columns (for columns already in datetime format)\n",
    "        elif pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            date_cols[col] = {\"range\":(df[col].min(), df[col].max())}\n",
    "        \n",
    "        # Identify numerical columns\n",
    "        elif df[col].dtype in ['int64', 'float64']:\n",
    "            if df[col].nunique() < 5:\n",
    "                categorical_cols[col] = df[col].unique().tolist()\n",
    "            else:\n",
    "                numerical_cols[col] = {\"range\":(df[col].min(), df[col].max())}\n",
    "\n",
    "    return {\"categorial_columns\": categorical_cols, \"numerical_columns\": numerical_cols, \"date_columns\": date_cols}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46fc331-ea7c-4607-aa00-eeced4dcbde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plotly_graph(data_dict, additional_params=None, group_by=None, barmode=None):\n",
    "    # Extract information from the dictionary\n",
    "    x_axis = data_dict['x_axis']\n",
    "    y_axis = data_dict['y_axis']\n",
    "    chart_type = data_dict['chart_type']\n",
    "    df_str = data_dict['resultant_df']\n",
    "\n",
    "    # Converting the 'resultant_df' string to a DataFrame\n",
    "    if isinstance(df_str, str):\n",
    "        df = pd.read_csv(StringIO(df_str))\n",
    "    else:\n",
    "        df = df_str\n",
    "\n",
    "    for col in df.columns:\n",
    "        if isinstance(df[col].dtype, pd.IntervalDtype):\n",
    "            df[col] = df[col].apply(lambda x: str(x))\n",
    "\n",
    "    # Initialize a figure object\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Conditional logic based on chart type\n",
    "    if chart_type == 'bar':\n",
    "        return bar(chart_type=chart_type, df=df, x_axis=x_axis, y_axis=y_axis)\n",
    "    elif chart_type == 'grouped_bar':\n",
    "        return grouped_bar(result_df=df, x_axis=x_axis, y_axis=y_axis, group_by=group_by)\n",
    "    elif chart_type == 'line':\n",
    "        if group_by:\n",
    "            # Create a multiline chart\n",
    "            for name, group in df.groupby(group_by):\n",
    "                fig.add_trace(go.Scatter(x=group[x_axis], y=group[y_axis], mode='lines', name=name))\n",
    "        else:\n",
    "            # Create a standard line chart\n",
    "            fig.add_trace(go.Scatter(x=df[x_axis], y=df[y_axis], mode='lines'))\n",
    "            fig.update_layout(margin={'pad': 20}, xaxis_title=x_axis, yaxis_title=y_axis) \n",
    "\n",
    "    elif chart_type == 'scatter':\n",
    "        # Scatter plot\n",
    "        if group_by:\n",
    "            # Create a grouped scatter plot\n",
    "            for name, group in df.groupby(group_by):\n",
    "                fig.add_trace(go.Scatter(x=group[x_axis], y=group[y_axis], mode='markers', name=name))\n",
    "        else:\n",
    "            # Create a standard scatter plot\n",
    "            fig.add_trace(go.Scatter(x=df[x_axis], y=df[y_axis], mode='markers'))\n",
    "\n",
    "    elif chart_type == 'heatmap':\n",
    "        # Heatmap\n",
    "        fig.add_trace(go.Heatmap(z=df[y_axis], x=df[x_axis], y=df.index))\n",
    "\n",
    "    elif chart_type in ['area line', 'surface_area']:\n",
    "        # Area line chart logic\n",
    "        if group_by:\n",
    "            for name, group in df.groupby(group_by):\n",
    "                fig.add_trace(go.Scatter(x=group[x_axis], y=group[y_axis], fill='tozeroy', name=name))\n",
    "        else:\n",
    "            fig.add_trace(go.Scatter(x=df[x_axis], y=df[y_axis], fill='tozeroy'))\n",
    "\n",
    "    elif chart_type in ['multiline', 'multi_line']:\n",
    "        # Multiline chart logic\n",
    "        if group_by:\n",
    "            for name, group in df.groupby(group_by):\n",
    "                fig.add_trace(go.Scatter(x=group[x_axis], y=group[y_axis], mode='lines', name=name))\n",
    "        else:\n",
    "            fig.add_trace(go.Scatter(x=df[x_axis], y=df[y_axis], mode='lines'))\n",
    "        fig.update_layout(margin={'pad': 20}, xaxis_title=x_axis, yaxis_title=y_axis)\n",
    "\n",
    "    elif chart_type == 'scattercarpet':\n",
    "        # Scattercarpet plot logic\n",
    "        if group_by:\n",
    "            for name, group in df.groupby(group_by):\n",
    "                fig.add_trace(go.Scattercarpet(x=group[x_axis], y=group[y_axis], name=name))\n",
    "        else:\n",
    "            fig.add_trace(go.Scattercarpet(x=df[x_axis], y=df[y_axis]))\n",
    "\n",
    "    elif chart_type == 'stacked_bar':\n",
    "        for col in df.columns:\n",
    "            if col != x_axis:\n",
    "                fig.add_trace(go.Bar(x=df[x_axis], y=df[col], name=col, text=df[col], textposition='auto'))\n",
    "        barmode = barmode or 'stack'\n",
    "\n",
    "    else:\n",
    "        # Other chart types like pie, area, etc.\n",
    "        if chart_type == 'pie':\n",
    "            df = df.sort_values(by=y_axis, ascending=False)\n",
    "            labels, values = list(df[x_axis]), list(df[y_axis])\n",
    "            return pie_charts(labels=labels, values=values)\n",
    "        elif chart_type == 'area':\n",
    "            # Area chart logic\n",
    "            if group_by:\n",
    "                for name, group in df.groupby(group_by):\n",
    "                    fig.add_trace(go.Scatter(x=group[x_axis], y=group[y_axis], fill='tonexty', name=name))\n",
    "            else:\n",
    "                fig.add_trace(go.Scatter(x=df[x_axis], y=df[y_axis], fill='tonexty'))\n",
    "\n",
    "    fig.update_xaxes(title_text=data_dict['x_axis'])\n",
    "    fig.update_yaxes(title_text=data_dict['y_axis'])\n",
    "\n",
    "    # Update layout according to barmode and heading\n",
    "    if barmode:\n",
    "        fig.update_layout(barmode=barmode)\n",
    "\n",
    "    # If there are additional parameters, update the layout with them\n",
    "    if additional_params:\n",
    "        fig.update_layout(**additional_params)\n",
    "\n",
    "    fig.show()\n",
    "    json_config = json.loads(fig.to_json())\n",
    "\n",
    "    return json_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1e7acd-99d9-465f-bb25-f707b2fc9ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class PandasResultantDataframe:\n",
    "    '''\n",
    "    Class to execute required pandas code\n",
    "    '''\n",
    "\n",
    "    def __init__(self, chart_config, df, filter_columns):\n",
    "        self.chart_config = chart_config\n",
    "        self.df2 = df\n",
    "        self.freq_dict = {\n",
    "            'business_day': 'B', 'calendar_day': 'D', 'weekly': 'W', 'monthly': 'M', 'quarterly': 'Q',\n",
    "            'yearly': 'A', 'hourly': 'H', 'minutely': 'T', 'secondly': 'S', 'milliseconds': 'L',\n",
    "            'microseconds': 'U', 'nanoseconds': 'N'\n",
    "        }\n",
    "        self.filter_columns = filter_columns\n",
    "\n",
    "    def _apply_filters(self, df):\n",
    "        # Apply filters for numerical columns\n",
    "        for col, conditions in self.filter_columns.get('numerical_columns', {}).items():\n",
    "            start_value = conditions.get('start_value')\n",
    "            end_value = conditions.get('end_value')\n",
    "            if start_value is not None:\n",
    "                df = df[df[col] >= start_value]\n",
    "            if end_value is not None:\n",
    "                df = df[df[col] <= end_value]\n",
    "\n",
    "        # Apply filters for date columns\n",
    "        for col, conditions in self.filter_columns.get('date_columns', {}).items():\n",
    "            start_date = conditions.get('start_date')\n",
    "            end_date = conditions.get('end_date')\n",
    "            if start_date and end_date:\n",
    "                df[col] = pd.to_datetime(df[col])\n",
    "                df = df[(df[col] >= pd.to_datetime(start_date)) & (df[col] <= pd.to_datetime(end_date))]\n",
    "            elif start_date:\n",
    "                df = df[df[col] >= pd.to_datetime(start_date)]\n",
    "            elif end_date:\n",
    "                df = df[df[col] <= pd.to_datetime(end_date)]\n",
    "\n",
    "        # Apply filters for categorical columns\n",
    "        for col, values in self.filter_columns.get('categorical_columns', {}).items():\n",
    "            if values:\n",
    "                df = df[df[col].isin(values)]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def time_series_resultant_df(self):\n",
    "        x_axis = self.chart_config['x_axis']\n",
    "        y_axis = self.chart_config['y_axis']\n",
    "        operation = self.chart_config.get('operation', \"mean\")\n",
    "        df1 = self._apply_filters(self.df2.copy())\n",
    "        if \"binning\" in self.chart_config.keys():\n",
    "            binning = self.chart_config['binning']  ## yearly, monthly, daily\n",
    "            if binning == '':\n",
    "                binning = 'monthly'\n",
    "        elif df1.shape[0] > 720:\n",
    "            binning = 'yearly'\n",
    "        elif df1.shape[0] > 60:\n",
    "            binning = 'monthly'\n",
    "        else:\n",
    "            binning = 'daily'\n",
    "        # Ensure x_axis is datetime if it's not an integer\n",
    "        if df1[x_axis].dtype != \"int64\":\n",
    "            df1[x_axis] = pd.to_datetime(df1[x_axis])\n",
    "\n",
    "            if binning == 'quarterly':\n",
    "                # if df1[x_axis].dt.year.nunique() > 1:\n",
    "                # Include only the last year's data\n",
    "                #     last_year = df1[x_axis].dt.year.max()\n",
    "                #     df1_last_year = df1[df1[x_axis].dt.year == last_year]\n",
    "                #     df1_last_year['Quarter'] = df1_last_year[x_axis].dt.to_period('Q').astype(str)\n",
    "                #     resultant_df = df1_last_year.groupby('Quarter')[y_axis].agg(operation)\n",
    "                # last 4 quarters\n",
    "                #     last_4_quarters = sorted(df1[x_axis].dt.to_period('Q').unique())[-4:]\n",
    "                #     df1['Quarter'] = df1[x_axis].dt.to_period('Q').astype(str)\n",
    "                #     resultant_df = df1[df1[x_axis].dt.to_period('Q').isin(last_4_quarters)].groupby('Quarter')[y_axis].agg(operation)\n",
    "                # else:\n",
    "                #     df1['Quarter'] = df1[x_axis].dt.to_period('Q').dt.strftime('Q%q')\n",
    "                #     resultant_df = df1.groupby('Quarter')[y_axis].agg(operation)\n",
    "                ## For all years      \n",
    "                if df1[x_axis].dt.year.nunique() > 1:\n",
    "                    df1['Quarter'] = df1[x_axis].dt.to_period('Q').astype(str)\n",
    "                    resultant_df = df1.groupby('Quarter')[y_axis].agg(operation)\n",
    "                else:\n",
    "                    df1['Quarter'] = df1[x_axis].dt.to_period('Q').dt.strftime('Q%q')\n",
    "                    resultant_df = df1.groupby('Quarter')[y_axis].agg(operation)\n",
    "            else:\n",
    "                df1['binning'] = df1[x_axis].dt.to_period(self.freq_dict[binning]).dt.to_timestamp()\n",
    "                resultant_df = df1.groupby('binning')[y_axis].agg(operation)\n",
    "\n",
    "        else:\n",
    "            resultant_df = df1.groupby(x_axis)[y_axis].agg(operation)\n",
    "        resultant_df = resultant_df.reset_index()\n",
    "        resultant_df.columns = [x_axis, y_axis]\n",
    "\n",
    "        return resultant_df\n",
    "\n",
    "    def group_aggregates_resultant_df(self):\n",
    "        x_axis = self.chart_config['x_axis']\n",
    "        y_axis = self.chart_config['y_axis']\n",
    "        operation = self.chart_config.get('operation', \"mean\")\n",
    "        df1 = self._apply_filters(self.df2.copy())\n",
    "\n",
    "        if x_axis == y_axis:\n",
    "            resultant_df = df1.groupby(x_axis).size().reset_index(name='count')\n",
    "            self.chart_config['y_axis'] = 'count'\n",
    "        else:\n",
    "            resultant_df = df1.groupby(x_axis)[y_axis].agg(operation).reset_index()\n",
    "\n",
    "        return resultant_df\n",
    "\n",
    "    def combination_resultant_df(self):\n",
    "        chart_config = self.chart_config\n",
    "        df1 = self._apply_filters(self.df2.copy())\n",
    "        x_axis = chart_config['x_axis']\n",
    "        y_axis = chart_config['y_axis']\n",
    "        group_by = chart_config['group_by']\n",
    "    \n",
    "        if \"binning\" in self.chart_config.keys():\n",
    "            binning = self.chart_config['binning']  ## yearly, monthly, daily\n",
    "            if binning == '':\n",
    "                binning = 'monthly'\n",
    "        elif df1.shape[0] > 720:\n",
    "            binning = 'yearly'\n",
    "        elif df1.shape[0] > 60:\n",
    "            binning = 'monthly'\n",
    "        else:\n",
    "            binning = 'daily'\n",
    "\n",
    "        operation = self.chart_config.get('operation', \"mean\")\n",
    "\n",
    "        df1[x_axis] = pd.to_datetime(df1[x_axis])\n",
    "        df1[binning] = df1[x_axis].dt.strftime('%Y-%m')\n",
    "    \n",
    "        if binning == 'quarterly':\n",
    "            if df1[x_axis].dt.year.nunique() > 1:\n",
    "                df1['Quarter'] = df1[x_axis].dt.to_period('Q').astype(str)\n",
    "                resultant_df = df1.groupby(['Quarter', group_by])[y_axis].agg(operation).unstack().reset_index()\n",
    "                resultant_df = resultant_df.melt(id_vars=['Quarter'], var_name=group_by, value_name=y_axis)\n",
    "                resultant_df.columns = [x_axis, group_by, y_axis]\n",
    "            else:\n",
    "                df1['Quarter'] = df1[x_axis].dt.to_period('Q').dt.strftime('Q%q')\n",
    "                resultant_df = df1.groupby(['Quarter', group_by])[y_axis].agg(operation).unstack().reset_index()\n",
    "                resultant_df = resultant_df.melt(id_vars=['Quarter'], var_name=group_by, value_name=y_axis)\n",
    "                resultant_df.columns = [x_axis, group_by, y_axis]\n",
    "        else:\n",
    "            resultant_df = df1.groupby([binning, group_by])[y_axis].agg(operation).unstack().reset_index()\n",
    "            resultant_df = resultant_df.melt(id_vars=[binning], var_name=group_by, value_name=y_axis)\n",
    "            resultant_df.columns = [x_axis, group_by, y_axis]\n",
    "\n",
    "        return resultant_df\n",
    "\n",
    "\n",
    "    def multilevel_categorical(self):\n",
    "        df = self._apply_filters(self.df2.copy())\n",
    "        chart_config = self.chart_config\n",
    "        x_axis = chart_config.get(\"x_axis\")\n",
    "        y_axis = chart_config.get(\"y_axis\")\n",
    "        group_by = chart_config.get(\"group_by\")\n",
    "        operation = chart_config.get(\"operation\", \"mean\")\n",
    "        start_date = chart_config.get(\"start_date\", None)\n",
    "        end_date = chart_config.get(\"end_date\", None)\n",
    "\n",
    "        # Filter DataFrame based on start_date and end_date if provided\n",
    "        if start_date and end_date:\n",
    "            df = df[(df['Order_Date'] >= start_date) & (df['Order_Date'] <= end_date)]\n",
    "\n",
    "        # Perform groupby operation\n",
    "        if operation is None:\n",
    "            operation = 'mean'\n",
    "        if operation == 'mean':\n",
    "            result_df = df.groupby([x_axis, group_by])[y_axis].mean().reset_index()\n",
    "        elif operation == 'sum':\n",
    "            result_df = df.groupby([x_axis, group_by])[y_axis].sum().reset_index()\n",
    "        elif operation == 'count':\n",
    "            result_df = df.groupby([x_axis, group_by])[y_axis].count().reset_index()\n",
    "        else:\n",
    "            result_df = df.groupby([x_axis])[y_axis].agg(operation).reset_index()\n",
    "            self.chart_config['y_axis'] = 'count'\n",
    "\n",
    "        return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabbd208-7064-4b32-af09-765cd965fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_stock = pd.read_csv(\"../byob_test_datasets/E-commerce Dataset.csv\")\n",
    "global_stock_head = global_stock.head().to_csv(index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e991d4-c981-48b1-8c30-8b7d4d0268c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fa919c-59dd-4f0d-acba-37a4cfcd8350",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Order_Date': ['2018-01-01', '2018-02-01', '2018-03-01', '2018-04-01', '2018-05-01', '2018-06-01', \n",
    "                   '2018-07-01', '2018-08-01', '2018-09-01', '2018-10-01', '2018-11-01', '2018-12-01',\n",
    "                   '2019-01-01', '2019-02-01', '2019-03-01', '2019-04-01', '2019-05-01', '2019-06-01', \n",
    "                   '2019-07-01', '2019-08-01', '2019-09-01', '2019-10-01', '2019-11-01', '2019-12-01',\n",
    "                   '2020-01-01', '2020-02-01', '2020-03-01', '2020-04-01', '2020-05-01', '2020-06-01', \n",
    "                   '2020-07-01', '2020-08-01', '2020-09-01', '2020-10-01', '2020-11-01', '2020-12-01'],\n",
    "    'Profit': [200000, 300000, 250000, 300000, 400000, 350000, 350000, 300000, 250000, 375000, 400000, 250000,\n",
    "               220000, 320000, 270000, 310000, 420000, 370000, 360000, 310000, 260000, 385000, 410000, 260000,\n",
    "               230000, 330000, 280000, 320000, 430000, 380000, 370000, 320000, 270000, 395000, 420000, 270000],\n",
    "}\n",
    "\n",
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd02651a-d8cf-4f9b-b6a5-c9b5d2e532c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Yearly Loan Approval Trend by State\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7169dbf-f52a-4328-b549-e76556cc340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_config ={'x_axis': 'Order_Date',\n",
    " 'y_axis': 'Profit',\n",
    " 'binning': 'quarterly',\n",
    " 'heading': 'Quarterly Profit Trend by Order_Date',\n",
    " 'group_by': '',\n",
    " 'operation': 'sum',\n",
    " 'chart_type': 'line',\n",
    " 'start_date': None,\n",
    " 'end_date': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4dee43-bf31-4b50-92b2-597d4b4fe495",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_resultant_df = PandasResultantDataframe(chart_config,global_stock,filter_columns={})\n",
    "resultant_df = pandas_resultant_df.time_series_resultant_df()\n",
    "chart_config['resultant_df'] = resultant_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2ddc29-26b5-40f9-a39b-f751ed696131",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a23dc7-d08c-4392-8cb3-8da547793462",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plotly_graph(chart_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feef99a-6b53-418c-8be0-8ec32636353f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
